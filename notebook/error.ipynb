{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c4d61fc-85c1-41a5-a90a-8f7d3cef5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 16 02:26:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   35C    P8    19W / 300W |   7763MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef23f706-f84a-4274-a21f-62d3ceb0b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"commonlit-exp003-deberta-v3-base\"\n",
    "    MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "    ROOT = \"/notebooks\"\n",
    "\n",
    "    apex=True\n",
    "    seed = 42\n",
    "    num_fold = 4\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    batch_size = 16\n",
    "    n_epochs = 3\n",
    "    max_len = 512\n",
    "    target_list = [\"content\", \"wording\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e005db68-c9ac-4d8f-9cf0-0ad993be0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.1+cu113 in /usr/local/lib/python3.9/dist-packages (1.10.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1+cu113) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: text-unidecode in /usr/local/lib/python3.9/dist-packages (1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "! pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "!pip install text-unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab3cbd-a73c-4b3f-aee6-cf7b3bb3e257",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14a32846-749b-4981-bd31-94c4beeb650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install -qq transformers==4.16.2\n",
    "    ! pip install -qq tokenizers==0.11.6\n",
    "    ! pip install -qq transformers[sentencepiece]\n",
    "\n",
    "    # set dirs    \n",
    "    cfg.INPUT = Path(f\"{cfg.ROOT}/input\")\n",
    "    cfg.OUTPUT = Path(f\"{cfg.ROOT}/output\")\n",
    "    cfg.EXP = cfg.OUTPUT / cfg.NAME\n",
    "\n",
    "    cfg.api_path = f\"{cfg.ROOT}/kaggle.json\"\n",
    "\n",
    "    cfg.EXP_MODEL = cfg.EXP / \"model\"\n",
    "    cfg.EXP_FIG = cfg.EXP / \"fig\"\n",
    "    cfg.EXP_PREDS = cfg.EXP / \"preds\"\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
    "        d.mkdir(exist_ok=True)\n",
    "        \n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    for key in dataset_metadata.keys():\n",
    "        if isinstance(dataset_metadata[key], PosixPath):\n",
    "            dataset_metadata[key] = str(dataset_metadata[key])\n",
    "    with open(Path(upload_dir / 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0215b90-d40f-4e2b-bccb-c516afb12c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df):\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        print(f\"{column} rmse:\", score)\n",
    "        all_score += score/len(cfg.target_list)\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba9659-8a32-4eae-abe5-3bb09fbd1fb4",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "393a583a-01fa-47fe-ad15-d26a818e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train = pd.read_csv(cfg.INPUT / \"summaries_train.csv\")\n",
    "prompts_train = pd.read_csv(cfg.INPUT / \"prompts_train.csv\")\n",
    "train = train.merge(prompts_train, on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25d092b7-3eb3-4eaf-96a3-98bca99cae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.load(cfg.EXP_PREDS / \"oof_pred.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d4b268e-73e1-4b9e-bb14-dde430ecb505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 1.3623506960009386\n",
      "wording rmse: 1.3197456230385771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3410481595197579"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcrmse(cfg, oof, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80eeb97-f21d-45f4-b303-119081472305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
