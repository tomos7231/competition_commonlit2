{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q pyspellchecker textstat text-unidecode kaggle\n",
    "! pip install -q torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"commonlit-exp025-gte-base\"\n",
    "    MODEL_PATH = \"thenlper/gte-base\"\n",
    "    ROOT = \"/notebooks\"\n",
    "\n",
    "    seed = 42\n",
    "    num_fold = 1\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    batch_size = 16\n",
    "    n_epochs = 5\n",
    "    target = \"content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from pathlib import PosixPath\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import textstat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install -qq transformers==4.16.2\n",
    "    ! pip install -qq tokenizers==0.11.6\n",
    "    ! pip install -qq transformers[sentencepiece]\n",
    "    ! pip install -qq sentence_transformers\n",
    "\n",
    "    # set dirs    \n",
    "    cfg.INPUT = Path(f\"{cfg.ROOT}/input\")\n",
    "    cfg.OUTPUT = Path(f\"{cfg.ROOT}/output\")\n",
    "    cfg.EXP = cfg.OUTPUT / cfg.NAME\n",
    "\n",
    "    cfg.api_path = f\"{cfg.ROOT}/kaggle.json\"\n",
    "\n",
    "    cfg.EXP_MODEL = cfg.EXP / \"model\"\n",
    "    cfg.EXP_FIG = cfg.EXP / \"fig\"\n",
    "    cfg.EXP_PREDS = cfg.EXP / \"preds\"\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
    "        d.mkdir(exist_ok=True)\n",
    "        \n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Utils\n",
    "# =====================\n",
    "# Seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# KFold\n",
    "def get_kfold(train, n_splits, seed):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train)\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_stratifiedkfold(train, target_col, n_splits, seed):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_groupkfold(train, target_col, group_col, n_splits):\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "    generator = kf.split(train, train[target_col], train[group_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n",
    "    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col], train[group_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n",
    "    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_commonlit_fold(train):\n",
    "    id2fold = {\n",
    "        \"814d6b\": 0,\n",
    "        \"39c16e\": 1,\n",
    "        \"3b9047\": 2,\n",
    "        \"ebad26\": 3,\n",
    "    }\n",
    "    train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n",
    "    return train[\"fold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df, verbose = True):\n",
    "    scores = []\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        if verbose:\n",
    "            print(f\"{column} rmse:\", score)\n",
    "        all_score += score/len(cfg.target_list)\n",
    "        scores.append(score)\n",
    "    return all_score, scores[0], scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_mapping = {\n",
    "    'studentdesigned': 'student designed',\n",
    "    'teacherdesigned': 'teacher designed',\n",
    "    'genericname': 'generic name',\n",
    "    'winnertakeall': 'winner take all',\n",
    "    'studentname': 'student name',\n",
    "    'driveless': 'driverless',\n",
    "    'teachername': 'teacher name',\n",
    "    'propername': 'proper name',\n",
    "    'bestlaid': 'best laid',\n",
    "    'genericschool': 'generic school',\n",
    "    'schoolname': 'school name',\n",
    "    'winnertakesall': 'winner take all',\n",
    "    'elctoral': 'electoral',\n",
    "    'eletoral': 'electoral',\n",
    "    'genericcity': 'generic city',\n",
    "    'elctors': 'electoral',\n",
    "    'venuse': 'venue',\n",
    "    'blimplike': 'blimp like',\n",
    "    'selfdriving': 'self driving',\n",
    "    'electorals': 'electoral',\n",
    "    'nearrecord': 'near record',\n",
    "    'egyptianstyle': 'egyptian style',\n",
    "    'oddnumbered': 'odd numbered',\n",
    "    'carintensive': 'car intensive',\n",
    "    'elecoral': 'electoral',\n",
    "    'oction': 'auction',\n",
    "    'electroal': 'electoral',\n",
    "    'evennumbered': 'even numbered',\n",
    "    'mesalandforms': 'mesa landforms',\n",
    "    'electoralvote': 'electoral vote',\n",
    "    'relativename': 'relative name',\n",
    "    '22euro': 'twenty two euro',\n",
    "    'ellectoral': 'electoral',\n",
    "    'thirtyplus': 'thirty plus',\n",
    "    'collegewon': 'college won',\n",
    "    'hisher': 'higher',\n",
    "    'teacherbased': 'teacher based',\n",
    "    'computeranimated': 'computer animated',\n",
    "    'canadidate': 'candidate',\n",
    "    'studentbased': 'student based',\n",
    "    'gorethanks': 'gore thanks',\n",
    "    'clouddraped': 'cloud draped',\n",
    "    'edgarsnyder': 'edgar snyder',\n",
    "    'emotionrecognition': 'emotion recognition',\n",
    "    'landfrom': 'land form',\n",
    "    'fivedays': 'five days',\n",
    "    'electoal': 'electoral',\n",
    "    'lanform': 'land form',\n",
    "    'electral': 'electoral',\n",
    "    'presidentbut': 'president but',\n",
    "    'teacherassigned': 'teacher assigned',\n",
    "    'beacuas': 'because',\n",
    "    'positionestimating': 'position estimating',\n",
    "    'selfeducation': 'self education',\n",
    "    'diverless': 'driverless',\n",
    "    'computerdriven': 'computer driven',\n",
    "    'outofcontrol': 'out of control',\n",
    "    'faultthe': 'fault the',\n",
    "    'unfairoutdated': 'unfair outdated',\n",
    "    'aviods': 'avoid',\n",
    "    'momdad': 'mom dad',\n",
    "    'statesbig': 'states big',\n",
    "    'presidentswing': 'president swing',\n",
    "    'inconclusion': 'in conclusion',\n",
    "    'handsonlearning': 'hands on learning',\n",
    "    'electroral': 'electoral',\n",
    "    'carowner': 'car owner',\n",
    "    'elecotral': 'electoral',\n",
    "    'studentassigned': 'student assigned',\n",
    "    'collegefive': 'college five',\n",
    "    'presidant': 'president',\n",
    "    'unfairoutdatedand': 'unfair outdated and',\n",
    "    'nixonjimmy': 'nixon jimmy',\n",
    "    'canadates': 'candidate',\n",
    "    'tabletennis': 'table tennis',\n",
    "    'himher': 'him her',\n",
    "    'studentsummerpacketdesigners': 'student summer packet designers',\n",
    "    'studentdesign': 'student designed',\n",
    "    'limting': 'limiting',\n",
    "    'electrol': 'electoral',\n",
    "    'campaignto': 'campaign to',\n",
    "    'presendent': 'president',\n",
    "    'thezebra': 'the zebra',\n",
    "    'landformation': 'land formation',\n",
    "    'eyetoeye': 'eye to eye',\n",
    "    'selfreliance': 'self reliance',\n",
    "    'studentdriven': 'student driven',\n",
    "    'winnertake': 'winner take',\n",
    "    'alliens': 'aliens',\n",
    "    '2000but': '2000 but',\n",
    "    'electionto': 'election to',\n",
    "    'candidatesas': 'candidates as',\n",
    "    'electers': 'electoral',\n",
    "    'winnertakes': 'winner takes',\n",
    "    'isfeet': 'is feet',\n",
    "    'incar': 'incur',\n",
    "    'wellconstructed': 'well constructed',\n",
    "    'craftsmenwomen': 'crafts men women',\n",
    "    'freelunch': 'free lunch',\n",
    "    'twothousandrevolutions': 'two thousand revolutions',\n",
    "    'ushistoryorg': 'us history org',\n",
    "    'pharohs': 'pharaohs',\n",
    "    'whitehot': 'white hot',\n",
    "    'vizers': 'visors',\n",
    "    'mrjones': 'mr jones',\n",
    "    'aminute': 'a minute',\n",
    "    'spoiledmeat': 'spoiled meat',\n",
    "    'farmersgave': 'farmers gave',\n",
    "    'spolied': 'spoiled',\n",
    "    'tradgey': 'tragedy',\n",
    "    'pyrimid': 'pyramid',\n",
    "    'pyrimad': 'pyramid',\n",
    "    'egyptiansfrom': 'egyptians from',\n",
    "    'harvestthats': 'harvest that',\n",
    "    'expierment': 'experiment',\n",
    "    'jestthat': 'jest that',\n",
    "    'twothousandrevolutionsaminute': 'two thousand revolutions a minute',\n",
    "    'expirament': 'experiment',\n",
    "    'nonspoiled': 'non spoiled',\n",
    "    'egyptains': 'egyptians',\n",
    "    'tragedys': 'tragedy',\n",
    "    'pyrmaid': 'pyramid',\n",
    "    'expirment': 'experiment',\n",
    "    'whiteit': 'grade there',\n",
    "    'gradethere': 'tragedy',\n",
    "    'goverement': 'government',\n",
    "    'godsthe': 'gods the',\n",
    "    'paraoh': 'pharaoh',\n",
    "    'classesupper': 'classes upper',\n",
    "    'pharoes': 'pharaohs',\n",
    "    'noblespriests': 'noble priests',\n",
    "    'farmersslaves': 'farmers slaves',\n",
    "    'harvestâ€”thatâ€™s': 'harvest that',\n",
    "    'tradedy': 'tragedy',\n",
    "    'paraohs': 'pharaohs',\n",
    "    'paragrapgh': 'paragraph',\n",
    "    'expieriment': 'experiment',\n",
    "    'tragdey': 'tragedy',\n",
    "    'pyramaid': 'pyramid',\n",
    "    'pyrmid': 'pyramid',\n",
    "    'prists': 'priests',\n",
    "    'pharoas': 'pharaohs',\n",
    "    'priets': 'priests',\n",
    "    'pharoph': 'pharaohs',\n",
    "    'pharaoah': 'pharaohs',\n",
    "    'pharahos': 'pharaohs',\n",
    "    'pharaohthe': 'pharaohs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontraction(phrase):\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"he's\", \"he is\", phrase)\n",
    "    phrase = re.sub(r\"there's\", \"there is\", phrase)\n",
    "    phrase = re.sub(r\"We're\", \"We are\", phrase)\n",
    "    phrase = re.sub(r\"That's\", \"That is\", phrase)\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"they're\", \"they are\", phrase)\n",
    "    phrase = re.sub(r\"Can't\", \"Cannot\", phrase)\n",
    "    phrase = re.sub(r\"wasn't\", \"was not\", phrase)\n",
    "    phrase = re.sub(r\"don\\x89Ûªt\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"donãât\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"aren't\", \"are not\", phrase)\n",
    "    phrase = re.sub(r\"isn't\", \"is not\", phrase)\n",
    "    phrase = re.sub(r\"What's\", \"What is\", phrase)\n",
    "    phrase = re.sub(r\"haven't\", \"have not\", phrase)\n",
    "    phrase = re.sub(r\"hasn't\", \"has not\", phrase)\n",
    "    phrase = re.sub(r\"There's\", \"There is\", phrase)\n",
    "    phrase = re.sub(r\"He's\", \"He is\", phrase)\n",
    "    phrase = re.sub(r\"It's\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"You're\", \"You are\", phrase)\n",
    "    phrase = re.sub(r\"I'M\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"shouldn't\", \"should not\", phrase)\n",
    "    phrase = re.sub(r\"wouldn't\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"i'm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"I'm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"Isn't\", \"is not\", phrase)\n",
    "    phrase = re.sub(r\"Here's\", \"Here is\", phrase)\n",
    "    phrase = re.sub(r\"you've\", \"you have\", phrase)\n",
    "    phrase = re.sub(r\"you\\x89Ûªve\", \"you have\", phrase)\n",
    "    phrase = re.sub(r\"we're\", \"we are\", phrase)\n",
    "    phrase = re.sub(r\"what's\", \"what is\", phrase)\n",
    "    phrase = re.sub(r\"couldn't\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"we've\", \"we have\", phrase)\n",
    "    phrase = re.sub(r\"it\\x89Ûªs\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"doesn\\x89Ûªt\", \"does not\", phrase)\n",
    "    phrase = re.sub(r\"It\\x89Ûªs\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"Here\\x89Ûªs\", \"Here is\", phrase)\n",
    "    phrase = re.sub(r\"who's\", \"who is\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªve\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"y'all\", \"you all\", phrase)\n",
    "    phrase = re.sub(r\"can\\x89Ûªt\", \"cannot\", phrase)\n",
    "    phrase = re.sub(r\"would've\", \"would have\", phrase)\n",
    "    phrase = re.sub(r\"it'll\", \"it will\", phrase)\n",
    "    phrase = re.sub(r\"we'll\", \"we will\", phrase)\n",
    "    phrase = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"We've\", \"We have\", phrase)\n",
    "    phrase = re.sub(r\"he'll\", \"he will\", phrase)\n",
    "    phrase = re.sub(r\"Y'all\", \"You all\", phrase)\n",
    "    phrase = re.sub(r\"Weren't\", \"Were not\", phrase)\n",
    "    phrase = re.sub(r\"Didn't\", \"Did not\", phrase)\n",
    "    phrase = re.sub(r\"they'll\", \"they will\", phrase)\n",
    "    phrase = re.sub(r\"they'd\", \"they would\", phrase)\n",
    "    phrase = re.sub(r\"DON'T\", \"DO NOT\", phrase)\n",
    "    phrase = re.sub(r\"That\\x89Ûªs\", \"That is\", phrase)\n",
    "    phrase = re.sub(r\"they've\", \"they have\", phrase)\n",
    "    phrase = re.sub(r\"i'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"should've\", \"should have\", phrase)\n",
    "    phrase = re.sub(r\"You\\x89Ûªre\", \"You are\", phrase)\n",
    "    phrase = re.sub(r\"where's\", \"where is\", phrase)\n",
    "    phrase = re.sub(r\"Don\\x89Ûªt\", \"Do not\", phrase)\n",
    "    phrase = re.sub(r\"we'd\", \"we would\", phrase)\n",
    "    phrase = re.sub(r\"i'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"weren't\", \"were not\", phrase)\n",
    "    phrase = re.sub(r\"They're\", \"They are\", phrase)\n",
    "    phrase = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", phrase)\n",
    "    phrase = re.sub(r\"you\\x89Ûªll\", \"you will\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"let's\", \"let us\", phrase)\n",
    "    phrase = re.sub(r\"it's\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"can't\", \"cannot\", phrase)\n",
    "    phrase = re.sub(r\"don't\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"you're\", \"you are\", phrase)\n",
    "    phrase = re.sub(r\"i've\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"that's\", \"that is\", phrase)\n",
    "    phrase = re.sub(r\"i'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"doesn't\", \"does not\",phrase)\n",
    "    phrase = re.sub(r\"i'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"didn't\", \"did not\", phrase)\n",
    "    phrase = re.sub(r\"ain't\", \"am not\", phrase)\n",
    "    phrase = re.sub(r\"you'll\", \"you will\", phrase)\n",
    "    phrase = re.sub(r\"I've\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"Don't\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"I'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"I'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"Let's\", \"Let us\", phrase)\n",
    "    phrase = re.sub(r\"you'd\", \"You would\", phrase)\n",
    "    phrase = re.sub(r\"It's\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"Ain't\", \"am not\", phrase)\n",
    "    phrase = re.sub(r\"Haven't\", \"Have not\", phrase)\n",
    "    phrase = re.sub(r\"Could've\", \"Could have\", phrase)\n",
    "    phrase = re.sub(r\"youve\", \"you have\", phrase)  \n",
    "    phrase = re.sub(r\"donå«t\", \"do not\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = decontraction(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_misspell(text):\n",
    "    for bad_word in misspell_mapping:\n",
    "        if bad_word in text:\n",
    "            text = text.replace(bad_word, misspell_mapping[bad_word])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_features(df):\n",
    "    df['processed_text'] = df['text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "    df['processed_text'] = df['processed_text'].apply(lambda x : clean_text(x))\n",
    "    df['processed_text'] = df['processed_text'].apply(lambda x : clean_misspell(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(cfg, valid_df, scaler, model):\n",
    "    val_pred = []\n",
    "    \n",
    "    for _, row in valid_df.iterrows():\n",
    "        prompt_text = row.prompt_text\n",
    "        summary_text = row.processed_text\n",
    "        \n",
    "        # get embeddings\n",
    "        vec_prompt = model.encode(prompt_text)\n",
    "        vec_summary = model.encode(summary_text)\n",
    "        \n",
    "        # cos_sim\n",
    "        score = cosine_similarity([vec_prompt], [vec_summary])[0][0]\n",
    "        \n",
    "        # 戻す\n",
    "        pred = scaler.inverse_transform(score.reshape(-1, 1))\n",
    "        \n",
    "        val_pred.append(pred[0, 0])\n",
    "        \n",
    "    val_pred = np.array(val_pred)\n",
    "        \n",
    "    # スコア計算\n",
    "    rmse = mean_squared_error(val_pred, valid_df[cfg.target].values, squared = False)\n",
    "    \n",
    "    print(val_pred.shape)\n",
    "    \n",
    "    return rmse, val_pred\n",
    "\n",
    "def training(cfg, train):\n",
    "    # =====================\n",
    "    # Training\n",
    "    # =====================\n",
    "    set_seed(cfg.seed)\n",
    "    oof_pred = np.zeros(len(train), dtype=np.float32)\n",
    "    fold_score = []\n",
    "\n",
    "    for fold in cfg.trn_fold:\n",
    "        # dataset, dataloader\n",
    "        train_df = train.loc[cfg.folds!=fold]\n",
    "        valid_df = train.loc[cfg.folds==fold]\n",
    "        train_idx = list(train_df.index)\n",
    "        valid_idx = list(valid_df.index)\n",
    "        \n",
    "        # train_dfのcontent scoreを正規化\n",
    "        scaler = MinMaxScaler()\n",
    "        train_df[\"scaled_content\"] = scaler.fit_transform(train_df[cfg.target].values.reshape(-1, 1))\n",
    "        valid_df[\"scaled_content\"] = scaler.transform(valid_df[cfg.target].values.reshape(-1, 1))\n",
    "        \n",
    "        # InputExamples\n",
    "        train_examples = [InputExample(texts = [row[\"prompt_text\"], row[\"processed_text\"]], label = row[\"scaled_content\"])\n",
    "                         for _, row in train_df.iterrows()]\n",
    "        \n",
    "        # Valid\n",
    "        valid_sentence1 = valid_df[\"prompt_text\"].values.tolist()\n",
    "        valid_sentence2 = valid_df[\"processed_text\"].values.tolist()\n",
    "        valid_scores = valid_df[\"scaled_content\"].values.tolist()\n",
    "        \n",
    "        evaluator = evaluation.EmbeddingSimilarityEvaluator(valid_sentence1, valid_sentence2, valid_scores)\n",
    "        \n",
    "        # DataLoader\n",
    "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=cfg.batch_size)\n",
    "        \n",
    "        # Model\n",
    "        model = SentenceTransformer(cfg.MODEL_PATH)\n",
    "        \n",
    "        # Loss\n",
    "        train_loss = losses.CosineSimilarityLoss(model)\n",
    "        \n",
    "        # model\n",
    "        warmup_steps = int(len(train_dataloader) * cfg.n_epochs * 0.1)\n",
    "        \n",
    "        model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "                 epochs=cfg.n_epochs,\n",
    "                 warmup_steps=warmup_steps,\n",
    "                 evaluator=evaluator,\n",
    "                 evaluation_steps=150,\n",
    "                 output_path=str(f\"{cfg.EXP_MODEL}/fold{fold}\"))\n",
    "        \n",
    "        model.save(str(f\"{cfg.EXP_MODEL}/fold{fold}\"))\n",
    "        \n",
    "        # evaluation\n",
    "        rmse, val_pred = evaluate(cfg, valid_df, scaler, model)\n",
    "        oof_pred[valid_idx] = val_pred\n",
    "        fold_score.append(rmse)\n",
    "        print(f\"fold{fold} rmse:\", rmse)\n",
    "        \n",
    "    np.save(cfg.EXP_PREDS / 'oof_pred.npy', oof_pred)\n",
    "    print(\"CV:\", np.mean(fold_score))\n",
    "    \n",
    "    return fold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train_df = pd.read_csv(cfg.INPUT / \"summaries_train.csv\").reset_index()\n",
    "prompts_train_df = pd.read_csv(cfg.INPUT / \"prompts_train.csv\")\n",
    "\n",
    "train_df = train_df.merge(prompts_train_df, on=\"prompt_id\")\n",
    "train_df = processing_features(train_df)\n",
    "train_df = train_df.sort_values(\"index\").reset_index(drop = True)\n",
    "\n",
    "cfg.folds = get_commonlit_fold(train_df)\n",
    "cfg.folds.to_csv(cfg.EXP_PREDS / 'folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33f294ab16a4d01b90f8261f631d259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28a86695f74e47b129939d1a1b028a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e55fbb05aa4cbcb5afb133c22ccbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26b74ccc10f4e24b3c0323bd9778373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24200f90483458fb8b003ef67e53160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e8a539fdfe499899ddbcb90ca93ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103,)\n",
      "fold0 rmse: 0.5793845250607528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e3d5b73877479ba300979a4ccdc612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112c081f9d8148ecb9c92a92277b7082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79b5740bd284bb1ae381671b7f60ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f806dc388134732a78aad1326e85e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db379b85550a44e5b6183b50c2ccacb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42718b7a8fd545439836634ccb67b121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2057,)\n",
      "fold1 rmse: 1.1462430529837353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c13951ff84436389615fc7c04fdf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12443f855cd4b6d92e8778a66cb81a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb セル 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training(cfg, train_df)\n",
      "\u001b[1;32m/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb セル 15\u001b[0m in \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m warmup_steps \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(train_dataloader) \u001b[39m*\u001b[39m cfg\u001b[39m.\u001b[39mn_epochs \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_objectives\u001b[39m=\u001b[39;49m[(train_dataloader, train_loss)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m          epochs\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mn_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m          warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m          evaluator\u001b[39m=\u001b[39;49mevaluator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m          evaluation_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m          output_path\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcfg\u001b[39m.\u001b[39;49mEXP_MODEL\u001b[39m}\u001b[39;49;00m\u001b[39m/fold\u001b[39;49m\u001b[39m{\u001b[39;49;00mfold\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mstr\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mEXP_MODEL\u001b[39m}\u001b[39;00m\u001b[39m/fold\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# evaluation\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sentence_transformers/SentenceTransformer.py:722\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     loss_value \u001b[39m=\u001b[39m loss_model(features, labels)\n\u001b[0;32m--> 722\u001b[0m     loss_value\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    723\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_model\u001b[39m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m    724\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_rebuild_wrapper_subclass, arg_wrapper_subclass)\n\u001b[1;32m    300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, no longer\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m# need to wrap with _TypedStorage\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     args \u001b[39m=\u001b[39m (\n\u001b[1;32m    304\u001b[0m         torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[1;32m    305\u001b[0m             wrap_storage\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped(),\n\u001b[1;32m    306\u001b[0m             dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype),\n\u001b[0;32m--> 307\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_offset(),\n\u001b[1;32m    308\u001b[0m         \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[1;32m    309\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride(),\n\u001b[1;32m    310\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad,\n\u001b[1;32m    311\u001b[0m         backward_hooks)  \u001b[39m# previously was self._backward_hooks\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_rebuild_tensor_v2, args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     if grad_tensors is None:\n\u001b[1;32m    153\u001b[0m         grad_tensors = grad_variables\n\u001b[0;32m--> 154\u001b[0m     else:\n\u001b[1;32m    155\u001b[0m         raise RuntimeError(\"'grad_tensors' and 'grad_variables' (deprecated) \"\n\u001b[1;32m    156\u001b[0m                            \"arguments both passed to backward(). Please only \"\n\u001b[1;32m    157\u001b[0m                            \"use 'grad_tensors'.\")\n\u001b[1;32m    158\u001b[0m if inputs is not None and len(inputs) == 0:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(cfg, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット作成\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "dataset_create_new(dataset_name = cfg.NAME, upload_dir = cfg.EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb セル 17\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# EXPフォルダを削除\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomoyayanagi/python/competicion_commonlit2/notebook/exp025_content.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m shutil\u001b[39m.\u001b[39mrmtree(cfg\u001b[39m.\u001b[39mEXP)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "# EXPフォルダを削除\n",
    "import shutil\n",
    "shutil.rmtree(cfg.EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
