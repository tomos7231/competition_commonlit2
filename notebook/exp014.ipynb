{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf29c80-f629-4a89-8ac9-55d250722bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pyspellchecker textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef23f706-f84a-4274-a21f-62d3ceb0b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"commonlit-exp014-deberta-v3-base\"\n",
    "    MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "    ROOT = \"/notebooks\"\n",
    "\n",
    "    apex=True\n",
    "    seed = 42\n",
    "    num_fold = 4\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    batch_size = 8\n",
    "    n_epochs = 3\n",
    "    max_len = 768\n",
    "    target_list = [\"content\", \"wording\"]\n",
    "    n_targets = len(target_list)\n",
    "    \n",
    "    weight_decay = 0.01\n",
    "    scheduler='cosine'\n",
    "    betas = (0.9, 0.999)\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    lr_weight_decay = 1.00\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    eval_step = 250\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps_rate=0.1\n",
    "    clip_grad_norm = 1000\n",
    "    gradient_accumulation_steps = 1\n",
    "    \n",
    "    # GPU Optimize Settings\n",
    "    gpu_optimize_config= {\n",
    "        \"freezing\": False,\n",
    "        \"gradient_checkpoint\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e005db68-c9ac-4d8f-9cf0-0ad993be0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.10.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1821.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1+cu113) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.10.1+cu113\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting text-unidecode\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: text-unidecode\n",
      "Successfully installed text-unidecode-1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import textstat\n",
    "\n",
    "! pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "!pip install text-unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab3cbd-a73c-4b3f-aee6-cf7b3bb3e257",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a32846-749b-4981-bd31-94c4beeb650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install -qq transformers==4.16.2\n",
    "    ! pip install -qq tokenizers==0.11.6\n",
    "    ! pip install -qq transformers[sentencepiece]\n",
    "\n",
    "    # set dirs    \n",
    "    cfg.INPUT = Path(f\"{cfg.ROOT}/input\")\n",
    "    cfg.OUTPUT = Path(f\"{cfg.ROOT}/output\")\n",
    "    cfg.EXP = cfg.OUTPUT / cfg.NAME\n",
    "\n",
    "    cfg.api_path = f\"{cfg.ROOT}/kaggle.json\"\n",
    "\n",
    "    cfg.EXP_MODEL = cfg.EXP / \"model\"\n",
    "    cfg.EXP_PREDS = cfg.EXP / \"preds\"\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP, cfg.EXP_MODEL, cfg.EXP_PREDS]:\n",
    "        d.mkdir(exist_ok=True)\n",
    "        \n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9b321-c43a-4428-99d5-430ca1917b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Utils\n",
    "# =====================\n",
    "# Seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_commonlit_fold(train):\n",
    "    id2fold = {\n",
    "        \"814d6b\": 0,\n",
    "        \"39c16e\": 1,\n",
    "        \"3b9047\": 2,\n",
    "        \"ebad26\": 3,\n",
    "    }\n",
    "    train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n",
    "    return train[\"fold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0215b90-d40f-4e2b-bccb-c516afb12c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df, verbose = True):\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        if verbose:\n",
    "            print(f\"{column} rmse:\", score)\n",
    "        all_score += score/len(cfg.target_list)\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6334798-8f53-419e-a378-63d8daeda473",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b7b941-e196-4349-8aac-c3e3ca796033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e4c1c0-9232-4d4b-87ff-bec7d91653f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_features(df):\n",
    "    df['processed_text'] = df['text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "    df['full_text'] = df[\"prompt_title\"] + \" [SEP] \" + df[\"prompt_question\"] + \" [SEP] \" + df[\"processed_text\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bbe092-fe6e-476c-9078-89ec1b419986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1f3cbe-9009-4b84-9cf3-96edc5d2f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1948,\n",
      "                 from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from /root/.cache/ipython/cython/_cython_magic_0507ba6f7af5325357e70c61fd0cf3f5.c:769:\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)  # Arrayの境界チェックを無効化\n",
    "@cython.wraparound(False)   # 負のインデックスを無効化\n",
    "def longest_common_substring(str s1, str s2):\n",
    "    cdef int m, n, i, j, longest\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    # Using numpy to initialize the 2D array\n",
    "    cdef cnp.ndarray[int, ndim=2] dp = np.zeros((m+1, n+1), dtype=np.int32)\n",
    "    \n",
    "    longest = 0\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                dp[i, j] = 0\n",
    "            elif s1[i - 1] == s2[j - 1]:\n",
    "                dp[i, j] = dp[i - 1, j - 1] + 1\n",
    "                longest = max(longest, dp[i, j])\n",
    "            else:\n",
    "                dp[i, j] = 0\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed161b0-daa1-46d7-831b-28280b2d4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotes_count(row):\n",
    "    text = row['text']\n",
    "    prompt_text = row['prompt_text']\n",
    "    quotes_from_text = re.findall(r'\"([^\"]*)\"', text)\n",
    "    if len(quotes_from_text)>0:\n",
    "        return [quote in prompt_text for quote in quotes_from_text].count(True)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ngram_co_occurrence(row, n=3):\n",
    "    text = row[\"text\"]\n",
    "    prompt_text = row[\"prompt_text\"]\n",
    "\n",
    "    text_ngram = set(zip(*[text[i:] for i in range(n)]))\n",
    "    prompt_ngram = set(zip(*[prompt_text[i:] for i in range(n)]))\n",
    "    return len(text_ngram & prompt_ngram)\n",
    "\n",
    "def feature_engineering(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # basic\n",
    "    output_df[\"n_words\"] = input_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    output_df[\"n_unique_words\"] = input_df[\"text\"].apply(lambda x: len(set(x.split())))\n",
    "    output_df[\"num_sentences\"] = input_df[\"text\"].apply(lambda x: len(x.split('.')))\n",
    "    output_df[\"is_upper\"] = input_df[\"text\"].apply(lambda x: x[0].isupper())\n",
    "    output_df[\"mean_num_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(e.split()) for e in x.split('.')]))\n",
    "    output_df[\"mean_num_unique_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(set(e.split())) for e in x.split('.')]))\n",
    "    output_df[\"num_slash\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\"))\n",
    "    output_df[\"paragraph_count\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\\n\"))\n",
    "    output_df[\"upper_count\"] = input_df[\"text\"].apply(lambda x: np.sum([w.isupper() for w in x.split()])/len(x.split()))\n",
    "    output_df[\"syntax_count\"] = input_df[\"text\"].apply(lambda x: x.count(\",\") + x.count(\"-\") + x.count(\";\") + x.count(\":\"))\n",
    "    output_df[\"vocab_strength\"] = output_df[\"n_unique_words\"] / output_df[\"n_words\"]\n",
    "    output_df[\"new_vocab\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) - set(x[\"prompt_text\"].split())), axis=1)\n",
    "\n",
    "    # compare\n",
    "    # overwrap word\n",
    "    output_df[\"n_overwrap_unique_word\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) & set(x[\"prompt_text\"].split())), axis=1)\n",
    "    # longest common substring\n",
    "    output_df[\"longest_common_substring\"] = input_df.apply(lambda x: longest_common_substring(x[\"text\"], x[\"prompt_text\"]), axis=1)\n",
    "    # quote\n",
    "    output_df[\"quote_count\"] = input_df.apply(quotes_count, axis=1)\n",
    "    # ngram co occurrence\n",
    "    for n in [3, 4, 5, 6, 7, 8]:\n",
    "        output_df[f\"n_co_occurrence_{n}\"] = input_df.apply(ngram_co_occurrence, n=n, axis=1) / output_df[\"n_words\"]\n",
    "    \n",
    "    \n",
    "    # misspell\n",
    "    spell = SpellChecker()\n",
    "    output_df[\"n_misspell\"] = input_df[\"text\"].apply(lambda x: len(spell.unknown(x.split())))\n",
    "\n",
    "\n",
    "    output_df['automated_readability_index'] = input_df[\"text\"].apply(lambda x: textstat.automated_readability_index(x))\n",
    "    output_df['coleman_liau_index'] = input_df[\"text\"].apply(lambda x: textstat.coleman_liau_index(x))\n",
    "    output_df['smog_index'] = input_df[\"text\"].apply(textstat.smog_index)\n",
    "    output_df['dale_chall_readability_score'] = input_df[\"text\"].apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "    output_df['linsear_write_formula'] = input_df[\"text\"].apply(lambda x: textstat.linsear_write_formula(x))\n",
    "    output_df['gunning_fog'] = input_df[\"text\"].apply(textstat.gunning_fog)\n",
    "    output_df['text_standard_float'] = input_df[\"text\"].apply(textstat.text_standard, float_output=True)\n",
    "    output_df['spache_readability'] = input_df[\"text\"].apply(textstat.spache_readability)\n",
    "    output_df['rix'] = input_df[\"text\"].apply(textstat.rix)\n",
    "    output_df['lix'] = input_df[\"text\"].apply(textstat.lix)\n",
    "\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49940cc-886e-4f5f-a17e-14ad2a007857",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a44555a-ba86-4e10-9295-4bc5a5b8c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['processed_text'].to_numpy()\n",
    "        self.labels = df[cfg.target_list].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.prepare_input(self.cfg, self.text[index])\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float)\n",
    "        return inputs, label\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(cfg, text):\n",
    "        inputs = cfg.tokenizer(text,\n",
    "                               add_special_tokens=True,\n",
    "                               max_length=cfg.max_len,\n",
    "                               padding=\"max_length\",\n",
    "                               truncation=True,\n",
    "                               return_offsets_mapping=False)\n",
    "        inputs['input_ids'] = torch.tensor(\n",
    "            inputs['input_ids'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs['attention_mask'] = torch.tensor(\n",
    "            inputs['attention_mask'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a4ac4-3afd-4793-944a-2f30ad185dc7",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d234a9-f3e5-4913-a040-1d5e76f90153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.gpu_optimize_config = cfg.gpu_optimize_config\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout\": 0.,\n",
    "                \"hidden_dropout_prob\": 0.,\n",
    "                \"attention_dropout\": 0.,\n",
    "                \"attention_probs_dropout_prob\": 0,\n",
    "            }\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            config=self.config\n",
    "        )\n",
    "\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, cfg.n_targets)\n",
    "        self._init_weights(self.fc)\n",
    "        self.ln = nn.LayerNorm(self.config.hidden_size)\n",
    "        self._init_weights(self.ln)\n",
    "\n",
    "        # Freeze\n",
    "        if self.gpu_optimize_config['freezing']:\n",
    "            freeze(self.backbone.encoder.layer[:8])\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if self.gpu_optimize_config['gradient_checkpoint']:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        last_state = outputs[0]\n",
    "        feature = self.pool(last_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        # batch, hidden_size\n",
    "        feature = self.feature(inputs)\n",
    "        # batch, 2\n",
    "        output = self.fc(self.ln(feature))\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.SmoothL1Loss(reduction='mean')\n",
    "            loss = loss_fct(output, labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216ad9a-d7f4-40bd-af0d-4ff0ff7499aa",
   "metadata": {},
   "source": [
    "# optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975ed9d1-27e5-49d9-9f6b-cf4de08469cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_grouped_parameters(cfg, model):\n",
    "    model_type = 'backbone'\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "             'lr': cfg.decoder_lr, 'weight_decay': 0.0},\n",
    "    ]\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "    layers.reverse()\n",
    "    lr = cfg.encoder_lr\n",
    "    for layer in layers:\n",
    "        lr *= cfg.lr_weight_decay\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": cfg.weight_decay,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b424bc0d-b830-4a5d-8982-2b74b8e4ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dffaa-01c5-40d5-a307-ce6d49478ebe",
   "metadata": {},
   "source": [
    "# eval,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dcde54a-4e69-4dd0-bd89-13585a68945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(cfg, valid_loader, model, valid_df, fold, best_val_preds, best_val_score):\n",
    "    val_preds = []\n",
    "    val_losses = []\n",
    "    val_nums = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n",
    "            for (inputs, labels) in pbar:\n",
    "                inputs = collate(inputs)\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(cfg.device)\n",
    "                labels = labels.to(cfg.device)\n",
    "                with autocast():\n",
    "                    loss, output = model(inputs, labels)\n",
    "                \n",
    "                output = output.detach().cpu().numpy()\n",
    "                val_preds.append(output)\n",
    "                val_losses.append(loss.item() * len(labels))\n",
    "                val_nums.append(len(labels))\n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': loss.item()\n",
    "                })\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_loss = sum(val_losses) / sum(val_nums)\n",
    "    score = mcrmse(cfg, val_preds, valid_df)\n",
    "\n",
    "    val_log = {\n",
    "        'val_loss': val_loss,\n",
    "        'mcrmse': score\n",
    "    }\n",
    "    display(val_log)\n",
    "\n",
    "    if best_val_score > score:\n",
    "        print('\\033[31m'+'save model weight'+'\\033[0m')\n",
    "        best_val_preds = val_preds\n",
    "        best_val_score = score\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            cfg.EXP_MODEL / f\"fold{fold}.pth\"\n",
    "        )\n",
    "    \n",
    "    return best_val_preds, best_val_score\n",
    "\n",
    "def training(cfg, train):\n",
    "    # =====================\n",
    "    # Training\n",
    "    # =====================\n",
    "    set_seed(cfg.seed)\n",
    "    oof_pred = np.zeros((len(train), 2), dtype=np.float32)\n",
    "    fold_score = []\n",
    "\n",
    "    for fold in cfg.trn_fold:\n",
    "        # dataset, dataloader\n",
    "        train_df = train.loc[cfg.folds!=fold]\n",
    "        valid_df = train.loc[cfg.folds==fold]\n",
    "        train_idx = list(train_df.index)\n",
    "        valid_idx = list(valid_df.index)\n",
    "\n",
    "        # Datasetの設定\n",
    "        train_dataset = TrainDataset(cfg, train_df)\n",
    "        valid_dataset = TrainDataset(cfg, valid_df)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # model\n",
    "        model = CustomModel(cfg)\n",
    "        torch.save(model.config, cfg.EXP_MODEL / 'config.pth')\n",
    "        model = model.to(cfg.device)\n",
    "\n",
    "        # optimizer, scheduler\n",
    "        optimizer_grouped_parameters = get_optimizer_grouped_parameters(cfg, model)\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        num_train_steps = int(len(train_df) / cfg.batch_size * cfg.n_epochs)\n",
    "        scheduler = get_scheduler(cfg, optimizer, num_train_steps)\n",
    "\n",
    "        # enable FGM\n",
    "        # fgm = FGM(model)\n",
    "\n",
    "        # model-training\n",
    "        best_val_preds = None\n",
    "        best_val_score = 9999\n",
    "        \n",
    "        for epoch in range(cfg.n_epochs):\n",
    "            # training\n",
    "            print(f\"# ============ start epoch:{epoch} ============== #\")\n",
    "            train_losses = []\n",
    "            train_nums = []\n",
    "            model.train() \n",
    "            scaler = GradScaler(enabled=cfg.apex)\n",
    "            with tqdm(train_loader, total=len(train_loader)) as pbar:\n",
    "                for step, (inputs, labels) in enumerate(pbar):\n",
    "                    inputs = collate(inputs)\n",
    "                    for k, v in inputs.items():\n",
    "                        inputs[k] = v.to(cfg.device)\n",
    "                    labels = labels.to(cfg.device)\n",
    "                    with autocast(enabled=cfg.apex):\n",
    "                        loss, output = model(inputs, labels)\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'loss': loss.item(),\n",
    "                        'lr': scheduler.get_lr()[0]\n",
    "                    })\n",
    "                    train_losses.append(loss.item() * len(labels))\n",
    "                    train_nums.append(len(labels))\n",
    "\n",
    "                    if cfg.gradient_accumulation_steps > 1:\n",
    "                        loss = loss / cfg.gradient_accumulation_steps\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    # FGM attack\n",
    "                    # fgm.attack()\n",
    "                    # with autocast(enabled=cfg.apex):\n",
    "                    #     loss_adv, _ = model(inputs, labels)\n",
    "                    # scaler.scale(loss_adv).backward()\n",
    "                    # fgm.restore()\n",
    "                    \n",
    "                    if cfg.clip_grad_norm is not None:\n",
    "                        # scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            model.parameters(),\n",
    "                            cfg.clip_grad_norm\n",
    "                        )\n",
    "                        \n",
    "                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        scheduler.step()\n",
    "\n",
    "                    if step % cfg.eval_step == 0 and step != 0:\n",
    "                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n",
    "                        best_val_preds, best_val_score = evaluating(\n",
    "                            cfg, valid_loader,\n",
    "                            model,\n",
    "                            valid_df,\n",
    "                            fold,\n",
    "                            best_val_preds,\n",
    "                            best_val_score,\n",
    "                        )\n",
    "                        model.train()\n",
    "\n",
    "            train_loss = sum(train_losses)/sum(train_nums)\n",
    "            train_log = {\n",
    "                'train_loss':train_loss\n",
    "            }\n",
    "            display(train_log)\n",
    "\n",
    "            # evaluating(epoch)\n",
    "            print(f'fold: {fold}, epoch: {epoch}, complete')\n",
    "            best_val_preds, best_val_score = evaluating(\n",
    "                cfg, valid_loader,\n",
    "                model,\n",
    "                valid_df,\n",
    "                fold,\n",
    "                best_val_preds,\n",
    "                best_val_score,\n",
    "            )\n",
    "\n",
    "        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n",
    "        np.save(cfg.EXP_PREDS / f'oof_pred_fold{fold}.npy', best_val_preds)\n",
    "        fold_score.append(best_val_score)\n",
    "        del model; gc.collect()\n",
    "\n",
    "    np.save(cfg.EXP_PREDS / 'oof_pred.npy', oof_pred)\n",
    "\n",
    "    # =====================\n",
    "    # scoring\n",
    "    # =====================\n",
    "    score = mcrmse(cfg, oof_pred, train)\n",
    "    print('fold score：', fold_score)\n",
    "    print('CV:', round(score, 4))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba9659-8a32-4eae-abe5-3bb09fbd1fb4",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393a583a-01fa-47fe-ad15-d26a818e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69b852500b14ccd960cbbb9aab12755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5678f2c552d348bc93a10c0753268f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ed4ab087ba40fc9a705ff7fd9ea486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef2bc4adc7341278c99166442a473aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adcf8840eab448f8d085fcbb5bf8e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a1ab2ac6d04ad4abefc5c520e132a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6372885843774461\n",
      "wording rmse: 1.1097331279598293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.3538652095379661, 'mcrmse': 0.8735108561686377}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 0, epoch: 0, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a946ea44a2464495d52da26769def1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6823698330200406\n",
      "wording rmse: 0.8077294913839268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.25309816564847853, 'mcrmse': 0.7450496622019838}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 0, epoch: 0, step: 750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d925385f5e4979993e832810f7bc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.525139758118734\n",
      "wording rmse: 0.7743063655095322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1985676421269653, 'mcrmse': 0.6497230618141332}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.18816954251304957}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a3ee17c5c4434a85ec129e0e486f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6160173667331398\n",
      "wording rmse: 0.7113794054296501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.202968161995586, 'mcrmse': 0.663698386081395}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026a986a02f040b1b17b87857df9fa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deccd5ae3194c01bd2cf4dce651c6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6839287947464997\n",
      "wording rmse: 0.7854921082255809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.25032219979726283, 'mcrmse': 0.7347104514860403}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfa7bf7c5db451893680e585718af05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6745092536890963\n",
      "wording rmse: 0.7327395101762103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22790548027048085, 'mcrmse': 0.7036243819326533}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, step: 750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7331cd65911d455195bfcf14960e93ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6648671503003692\n",
      "wording rmse: 0.7287846095922709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22487506648679267, 'mcrmse': 0.6968258799463201}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.08704172467623432}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f37dc32edb479aaae690a503ae97fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6584404188858177\n",
      "wording rmse: 0.7285152628052687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22270149619386936, 'mcrmse': 0.6934778408455432}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d889010c027e4544aecd4ad9f072e708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 2, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0c1de984044166bcea51d04f7e6876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.7183609339152519\n",
      "wording rmse: 0.7422605729332548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.24677163994755402, 'mcrmse': 0.7303107534242533}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 2, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7be43a15bd472d8094593139949f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6718924404345888\n",
      "wording rmse: 0.7098768814226324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.2203630633983197, 'mcrmse': 0.6908846609286106}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 2, step: 750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a90e98bc1f45b499d26c3a288a773d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.6767920261445747\n",
      "wording rmse: 0.7051064582057417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22024293102033551, 'mcrmse': 0.6909492421751582}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.0712686509245827}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 2, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c417b6aee4f548e6a393f43c6fa5bdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.676793163615436\n",
      "wording rmse: 0.7050952946498585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22023935468761033, 'mcrmse': 0.6909442291326473}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c537be4b65d40568f285f2822576e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 0, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5bcf6c989b47538b3a7844c81bd478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.46200709387820926\n",
      "wording rmse: 0.5782811294284023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.132043556385847, 'mcrmse': 0.5201441116533058}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 1, epoch: 0, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eb66ebae264fe2af81198ce738e62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4707496421115547\n",
      "wording rmse: 0.5605938729081836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13056922932171278, 'mcrmse': 0.5156717575098692}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.214672165003176}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3288690510aa40abab5a083a005f55c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.432843759313221\n",
      "wording rmse: 0.6629677057457314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.15278286763227386, 'mcrmse': 0.5479057325294762}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087447632e2c4388b3eef8b16d381ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 1, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cde40e888641be94fff1bab4bda9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.48795291268605306\n",
      "wording rmse: 0.5408720564416675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1303936908393736, 'mcrmse': 0.5144124845638602}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 1, epoch: 1, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1193d70b4ed143cc8300a9fd3d5aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.47500561349669546\n",
      "wording rmse: 0.523017372311028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.12264920418333185, 'mcrmse': 0.4990114929038617}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.1026648276406676}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2498a6d2b734c73a50f14c93055df9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4328235912891848\n",
      "wording rmse: 0.553042242338874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1212737739781587, 'mcrmse': 0.4929329168140294}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432802a2036c4840984f7593ef6fc552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 2, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e472e05a3f8f49839095f726de089386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.46320411070037293\n",
      "wording rmse: 0.5653217118161443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13119302196704363, 'mcrmse': 0.5142629112582586}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 2, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce08793460de429eaa932f6e334b2b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4788487273256214\n",
      "wording rmse: 0.5426228006855629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.12860420560505012, 'mcrmse': 0.5107357640055922}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.0794205038449187}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, epoch: 2, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724ad36567de442faf63c280ee32d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4771698701607572\n",
      "wording rmse: 0.5423240509107097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1281399262410724, 'mcrmse': 0.5097469605357334}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98399cb1f4b349159fc30fe3cbdedd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 0, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61def42a92fb4fb8925c0417e3f00d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5294715753231648\n",
      "wording rmse: 0.858349437652531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22237494618679648, 'mcrmse': 0.6939105064878479}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 2, epoch: 0, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b4dfafc72f4443a0ec61e37842f6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5064048166509861\n",
      "wording rmse: 0.9059995267009966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22603982603923783, 'mcrmse': 0.7062021716759914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.20006516476607192}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e02c4426f5441ab9e74c436d8f06f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5314162157100586\n",
      "wording rmse: 0.9509038214216939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.24968412371640658, 'mcrmse': 0.7411600185658762}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3491b963696a477682ad58f127f0810a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 1, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c331373d6cf4fde93fdd61f56d55127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.513380877105574\n",
      "wording rmse: 0.8169390464332797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.20086846603363412, 'mcrmse': 0.6651599617694268}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 2, epoch: 1, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d53521a52840ba8b5cd31f304f2ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5059068271149753\n",
      "wording rmse: 0.8387539968159675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.20505425628068852, 'mcrmse': 0.6723304119654714}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.09321750474584677}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6d7efdf51d4aa6b5111cead511c857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5190550345434779\n",
      "wording rmse: 0.8283427939915059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.20402798938878797, 'mcrmse': 0.6736989142674918}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd221a6c9b3a4af0a56728c7a3f4e89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 2, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074d9f0492fe4b1885adb44ce8bacba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.513474699165647\n",
      "wording rmse: 0.8349810449891792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.2042796978103011, 'mcrmse': 0.6742278720774131}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 2, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5578e1ff4ec41518ab647da52773043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5102843827791623\n",
      "wording rmse: 0.813533310088602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.19788845189586987, 'mcrmse': 0.6619088464338821}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.08017681020757426}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2, epoch: 2, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ec40c687a242409c8cca84c9f963bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5103831574825417\n",
      "wording rmse: 0.8164558686505056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.19870357769655017, 'mcrmse': 0.6634195130665237}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d0b657bce74643b3b8a52c4cff1eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 0, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a807a9dca7634863b8d776896967ff47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5348320408093356\n",
      "wording rmse: 0.6158846020938894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.16072988528049065, 'mcrmse': 0.5753583214516125}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 3, epoch: 0, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1918231eeb5b45d383f6df7e7a64e915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4608181483220685\n",
      "wording rmse: 0.6499260209009017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.15162715315818787, 'mcrmse': 0.5553720846114851}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.20707111064656047}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7f3362a13a46a7bf4b75d8363159b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.49533440921431354\n",
      "wording rmse: 0.5813773925095953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.14058857596290852, 'mcrmse': 0.5383559008619544}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dc64c6e4d34c459923536a073b4bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 1, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdc485fcf584c37acd64530f802a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.48266235638942256\n",
      "wording rmse: 0.5667391459699646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13330112025141716, 'mcrmse': 0.5247007511796935}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 3, epoch: 1, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4746111deed34b0388b3df58b982f62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.48012781167365964\n",
      "wording rmse: 0.5580516761751667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13077243615337508, 'mcrmse': 0.5190897439244132}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.1025908000496196}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08495ade74af40229494b256fec8eff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.48271992049631773\n",
      "wording rmse: 0.5446119342593468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.12881735668989844, 'mcrmse': 0.5136659273778323}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164ee4df49b84705ae28e1540e6cb063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 2, step: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98408d505fd4b55965eb0203fdae9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.5585296885375799\n",
      "wording rmse: 0.5531428459009462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.14967355845805877, 'mcrmse': 0.555836267219263}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 2, step: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb90701ee34187bab2d72180498764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4999716156850755\n",
      "wording rmse: 0.538900107539181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13144308410749167, 'mcrmse': 0.5194358616121283}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.07829516685795582}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3, epoch: 2, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3170bb85ee074f7da8d180775d681f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4996734346087254\n",
      "wording rmse: 0.540631370979542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13179804746039167, 'mcrmse': 0.5201524027941337}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4839007196378545\n",
      "wording rmse: 0.6695549118683936\n",
      "fold score： [0.6497230618141332, 0.4929329168140294, 0.6619088464338821, 0.5136659273778323]\n",
      "CV: 0.5767\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train_df = pd.read_csv(cfg.INPUT / \"summaries_train.csv\")\n",
    "prompts_train_df = pd.read_csv(cfg.INPUT / \"prompts_train.csv\")\n",
    "\n",
    "\n",
    "train_df = train_df.merge(prompts_train_df, on=\"prompt_id\")\n",
    "train_df = processing_features(train_df)\n",
    "train_feat_df = feature_engineering(train_df)\n",
    "\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n",
    "cfg.tokenizer.save_pretrained(cfg.EXP / 'tokenizer')\n",
    "cfg.folds = get_commonlit_fold(train_df)\n",
    "cfg.folds.to_csv(cfg.EXP_PREDS / 'folds.csv')\n",
    "score = training(cfg, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c069c-81db-4d5e-b4d6-36a7213ee92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d092b7-3eb3-4eaf-96a3-98bca99cae03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
