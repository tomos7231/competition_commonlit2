{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf29c80-f629-4a89-8ac9-55d250722bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pyspellchecker textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef23f706-f84a-4274-a21f-62d3ceb0b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"commonlit-exp013-deberta-v3-base\"\n",
    "    MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "    ROOT = \"/notebooks\"\n",
    "\n",
    "    apex=True\n",
    "    seed = 42\n",
    "    num_fold = 4\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    batch_size = 16\n",
    "    n_epochs = 3\n",
    "    max_len = 768\n",
    "    target_list = [\"content\", \"wording\"]\n",
    "    n_targets = len(target_list)\n",
    "    \n",
    "    weight_decay = 0.01\n",
    "    scheduler='cosine'\n",
    "    betas = (0.9, 0.999)\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    lr_weight_decay = 0.98\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    eval_step = 150\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps_rate=0.1\n",
    "    clip_grad_norm = 1000\n",
    "    gradient_accumulation_steps = 1\n",
    "    \n",
    "    # GPU Optimize Settings\n",
    "    gpu_optimize_config= {\n",
    "        \"freezing\": False,\n",
    "        \"gradient_checkpoint\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e005db68-c9ac-4d8f-9cf0-0ad993be0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.1+cu113 in /usr/local/lib/python3.9/dist-packages (1.10.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1+cu113) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: text-unidecode in /usr/local/lib/python3.9/dist-packages (1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import textstat\n",
    "\n",
    "! pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "!pip install text-unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab3cbd-a73c-4b3f-aee6-cf7b3bb3e257",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a32846-749b-4981-bd31-94c4beeb650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install -qq transformers==4.16.2\n",
    "    ! pip install -qq tokenizers==0.11.6\n",
    "    ! pip install -qq transformers[sentencepiece]\n",
    "\n",
    "    # set dirs    \n",
    "    cfg.INPUT = Path(f\"{cfg.ROOT}/input\")\n",
    "    cfg.OUTPUT = Path(f\"{cfg.ROOT}/output\")\n",
    "    cfg.EXP = cfg.OUTPUT / cfg.NAME\n",
    "\n",
    "    cfg.api_path = f\"{cfg.ROOT}/kaggle.json\"\n",
    "\n",
    "    cfg.EXP_MODEL = cfg.EXP / \"model\"\n",
    "    cfg.EXP_PREDS = cfg.EXP / \"preds\"\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP, cfg.EXP_MODEL, cfg.EXP_PREDS]:\n",
    "        d.mkdir(exist_ok=True)\n",
    "        \n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9b321-c43a-4428-99d5-430ca1917b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Utils\n",
    "# =====================\n",
    "# Seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_commonlit_fold(train):\n",
    "    id2fold = {\n",
    "        \"814d6b\": 0,\n",
    "        \"39c16e\": 1,\n",
    "        \"3b9047\": 2,\n",
    "        \"ebad26\": 3,\n",
    "    }\n",
    "    train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n",
    "    return train[\"fold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0215b90-d40f-4e2b-bccb-c516afb12c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df, verbose = True):\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        if verbose:\n",
    "            print(f\"{column} rmse:\", score)\n",
    "        all_score += score/len(cfg.target_list)\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6334798-8f53-419e-a378-63d8daeda473",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b7b941-e196-4349-8aac-c3e3ca796033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e4c1c0-9232-4d4b-87ff-bec7d91653f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_features(df):\n",
    "    df['processed_text'] = df['text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "    df['full_text'] = df[\"processed_text\"] + \" [SEP] \" + df[\"prompt_question\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bbe092-fe6e-476c-9078-89ec1b419986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1f3cbe-9009-4b84-9cf3-96edc5d2f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)  # Arrayの境界チェックを無効化\n",
    "@cython.wraparound(False)   # 負のインデックスを無効化\n",
    "def longest_common_substring(str s1, str s2):\n",
    "    cdef int m, n, i, j, longest\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    # Using numpy to initialize the 2D array\n",
    "    cdef cnp.ndarray[int, ndim=2] dp = np.zeros((m+1, n+1), dtype=np.int32)\n",
    "    \n",
    "    longest = 0\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                dp[i, j] = 0\n",
    "            elif s1[i - 1] == s2[j - 1]:\n",
    "                dp[i, j] = dp[i - 1, j - 1] + 1\n",
    "                longest = max(longest, dp[i, j])\n",
    "            else:\n",
    "                dp[i, j] = 0\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed161b0-daa1-46d7-831b-28280b2d4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotes_count(row):\n",
    "    text = row['text']\n",
    "    prompt_text = row['prompt_text']\n",
    "    quotes_from_text = re.findall(r'\"([^\"]*)\"', text)\n",
    "    if len(quotes_from_text)>0:\n",
    "        return [quote in prompt_text for quote in quotes_from_text].count(True)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ngram_co_occurrence(row, n=3):\n",
    "    text = row[\"text\"]\n",
    "    prompt_text = row[\"prompt_text\"]\n",
    "\n",
    "    text_ngram = set(zip(*[text[i:] for i in range(n)]))\n",
    "    prompt_ngram = set(zip(*[prompt_text[i:] for i in range(n)]))\n",
    "    return len(text_ngram & prompt_ngram)\n",
    "\n",
    "def feature_engineering(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # basic\n",
    "    output_df[\"n_words\"] = input_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    output_df[\"n_unique_words\"] = input_df[\"text\"].apply(lambda x: len(set(x.split())))\n",
    "    output_df[\"num_sentences\"] = input_df[\"text\"].apply(lambda x: len(x.split('.')))\n",
    "    output_df[\"mean_num_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(e.split()) for e in x.split('.')]))\n",
    "    output_df[\"mean_num_unique_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(set(e.split())) for e in x.split('.')]))\n",
    "    output_df[\"num_slash\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\"))\n",
    "    output_df[\"paragraph_count\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\\n\"))\n",
    "    output_df[\"upper_count\"] = input_df[\"text\"].apply(lambda x: np.sum([w.isupper() for w in x.split()])/len(x.split()))\n",
    "    output_df[\"syntax_count\"] = input_df[\"text\"].apply(lambda x: x.count(\",\") + x.count(\"-\") + x.count(\";\") + x.count(\":\"))\n",
    "    output_df[\"vocab_strength\"] = output_df[\"n_unique_words\"] / output_df[\"n_words\"]\n",
    "    output_df[\"new_vocab\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) - set(x[\"prompt_text\"].split())), axis=1)\n",
    "\n",
    "    # compare\n",
    "    # overwrap word\n",
    "    output_df[\"n_overwrap_unique_word\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) & set(x[\"prompt_text\"].split())), axis=1)\n",
    "    # longest common substring\n",
    "    output_df[\"longest_common_substring\"] = input_df.apply(lambda x: longest_common_substring(x[\"text\"], x[\"prompt_text\"]), axis=1)\n",
    "    # quote\n",
    "    output_df[\"quote_count\"] = input_df.apply(quotes_count, axis=1)\n",
    "    # ngram co occurrence\n",
    "    for n in [3, 4, 5, 6, 7, 8]:\n",
    "        output_df[f\"n_co_occurrence_{n}\"] = input_df.apply(ngram_co_occurrence, n=n, axis=1) / output_df[\"n_words\"]\n",
    "    \n",
    "    \n",
    "    # misspell\n",
    "    spell = SpellChecker()\n",
    "    output_df[\"n_misspell\"] = input_df[\"text\"].apply(lambda x: len(spell.unknown(x.split())))\n",
    "\n",
    "\n",
    "    output_df['automated_readability_index'] = input_df[\"text\"].apply(lambda x: textstat.automated_readability_index(x))\n",
    "    output_df['coleman_liau_index'] = input_df[\"text\"].apply(lambda x: textstat.coleman_liau_index(x))\n",
    "    output_df['smog_index'] = input_df[\"text\"].apply(textstat.smog_index)\n",
    "    output_df['dale_chall_readability_score'] = input_df[\"text\"].apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "    output_df['linsear_write_formula'] = input_df[\"text\"].apply(lambda x: textstat.linsear_write_formula(x))\n",
    "    output_df['gunning_fog'] = input_df[\"text\"].apply(textstat.gunning_fog)\n",
    "    output_df['text_standard_float'] = input_df[\"text\"].apply(textstat.text_standard, float_output=True)\n",
    "    output_df['spache_readability'] = input_df[\"text\"].apply(textstat.spache_readability)\n",
    "    output_df['rix'] = input_df[\"text\"].apply(textstat.rix)\n",
    "    output_df['lix'] = input_df[\"text\"].apply(textstat.lix)\n",
    "\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49940cc-886e-4f5f-a17e-14ad2a007857",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a44555a-ba86-4e10-9295-4bc5a5b8c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df, numerical_features_df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['processed_text'].to_numpy()\n",
    "        self.numerical_features = numerical_features_df.values\n",
    "        self.labels = df[cfg.target_list].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.prepare_input(self.cfg, self.text[index])\n",
    "        numerical_features = torch.tensor(self.numerical_features[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float)\n",
    "        return inputs, numerical_features, label\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(cfg, text):\n",
    "        inputs = cfg.tokenizer(text,\n",
    "                               add_special_tokens=True,\n",
    "                               max_length=cfg.max_len,\n",
    "                               padding=\"max_length\",\n",
    "                               truncation=True,\n",
    "                               return_offsets_mapping=False)\n",
    "        inputs['input_ids'] = torch.tensor(\n",
    "            inputs['input_ids'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs['attention_mask'] = torch.tensor(\n",
    "            inputs['attention_mask'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a4ac4-3afd-4793-944a-2f30ad185dc7",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d234a9-f3e5-4913-a040-1d5e76f90153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.gpu_optimize_config = cfg.gpu_optimize_config\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout\": 0.,\n",
    "                \"hidden_dropout_prob\": 0.,\n",
    "                \"attention_dropout\": 0.,\n",
    "                \"attention_probs_dropout_prob\": 0,\n",
    "            }\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            config=self.config\n",
    "        )\n",
    "\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size+31, cfg.n_targets)\n",
    "        self._init_weights(self.fc)\n",
    "\n",
    "        # Freeze\n",
    "        if self.gpu_optimize_config['freezing']:\n",
    "            freeze(self.backbone.encoder.layer[:8])\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if self.gpu_optimize_config['gradient_checkpoint']:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        last_state = outputs[0]\n",
    "        feature = self.pool(last_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, numerical_features, labels):\n",
    "        # batch, hidden_size\n",
    "        emb_feature = self.feature(inputs)\n",
    "        features = torch.cat([emb_feature, numerical_features], -1)\n",
    "        # batch, 2\n",
    "        output = self.fc(features)\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.SmoothL1Loss(reduction='mean')\n",
    "            loss = loss_fct(output, labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216ad9a-d7f4-40bd-af0d-4ff0ff7499aa",
   "metadata": {},
   "source": [
    "# optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975ed9d1-27e5-49d9-9f6b-cf4de08469cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_grouped_parameters(cfg, model):\n",
    "    model_type = 'backbone'\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "             'lr': cfg.decoder_lr, 'weight_decay': 0.0},\n",
    "    ]\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "    layers.reverse()\n",
    "    lr = cfg.encoder_lr\n",
    "    for layer in layers:\n",
    "        lr *= cfg.lr_weight_decay\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": cfg.weight_decay,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b424bc0d-b830-4a5d-8982-2b74b8e4ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dffaa-01c5-40d5-a307-ce6d49478ebe",
   "metadata": {},
   "source": [
    "# eval,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dcde54a-4e69-4dd0-bd89-13585a68945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(cfg, valid_loader, model, valid_df, fold, best_val_preds, best_val_score):\n",
    "    val_preds = []\n",
    "    val_losses = []\n",
    "    val_nums = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n",
    "            for (inputs, numerical_features, labels) in pbar:\n",
    "                inputs = collate(inputs)\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(cfg.device)\n",
    "                numerical_features = numerical_features.to(cfg.device)\n",
    "                labels = labels.to(cfg.device)\n",
    "                with autocast():\n",
    "                    loss, output = model(inputs, numerical_features, labels)\n",
    "                \n",
    "                output = output.detach().cpu().numpy()\n",
    "                val_preds.append(output)\n",
    "                val_losses.append(loss.item() * len(labels))\n",
    "                val_nums.append(len(labels))\n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': loss.item()\n",
    "                })\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_loss = sum(val_losses) / sum(val_nums)\n",
    "    score = mcrmse(cfg, val_preds, valid_df)\n",
    "\n",
    "    val_log = {\n",
    "        'val_loss': val_loss,\n",
    "        'mcrmse': score\n",
    "    }\n",
    "    display(val_log)\n",
    "\n",
    "    if best_val_score > score:\n",
    "        print('\\033[31m'+'save model weight'+'\\033[0m')\n",
    "        best_val_preds = val_preds\n",
    "        best_val_score = score\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            cfg.EXP_MODEL / f\"fold{fold}.pth\"\n",
    "        )\n",
    "    \n",
    "    return best_val_preds, best_val_score\n",
    "\n",
    "def training(cfg, train, train_feats):\n",
    "    # =====================\n",
    "    # Training\n",
    "    # =====================\n",
    "    set_seed(cfg.seed)\n",
    "    oof_pred = np.zeros((len(train), 2), dtype=np.float32)\n",
    "    fold_score = []\n",
    "\n",
    "    for fold in cfg.trn_fold:\n",
    "        # dataset, dataloader\n",
    "        train_df = train.loc[cfg.folds!=fold]\n",
    "        valid_df = train.loc[cfg.folds==fold]\n",
    "        train_feat_df = train_feats.loc[cfg.folds!=fold]\n",
    "        valid_feat_df = train_feats.loc[cfg.folds==fold]\n",
    "        train_idx = list(train_df.index)\n",
    "        valid_idx = list(valid_df.index)\n",
    "\n",
    "        # Datasetの設定\n",
    "        train_dataset = TrainDataset(cfg, train_df, train_feat_df)\n",
    "        valid_dataset = TrainDataset(cfg, valid_df, valid_feat_df)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # model\n",
    "        model = CustomModel(cfg)\n",
    "        torch.save(model.config, cfg.EXP_MODEL / 'config.pth')\n",
    "        model = model.to(cfg.device)\n",
    "\n",
    "        # optimizer, scheduler\n",
    "        optimizer_grouped_parameters = get_optimizer_grouped_parameters(cfg, model)\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        num_train_steps = int(len(train_df) / cfg.batch_size * cfg.n_epochs)\n",
    "        scheduler = get_scheduler(cfg, optimizer, num_train_steps)\n",
    "\n",
    "        # enable FGM\n",
    "        # fgm = FGM(model)\n",
    "\n",
    "        # model-training\n",
    "        best_val_preds = None\n",
    "        best_val_score = 9999\n",
    "        \n",
    "        for epoch in range(cfg.n_epochs):\n",
    "            # training\n",
    "            print(f\"# ============ start epoch:{epoch} ============== #\")\n",
    "            train_losses = []\n",
    "            train_nums = []\n",
    "            model.train() \n",
    "            scaler = GradScaler(enabled=cfg.apex)\n",
    "            with tqdm(train_loader, total=len(train_loader)) as pbar:\n",
    "                for step, (inputs, numerical_features, labels) in enumerate(pbar):\n",
    "                    inputs = collate(inputs)\n",
    "                    for k, v in inputs.items():\n",
    "                        inputs[k] = v.to(cfg.device)\n",
    "                    numerical_features = numerical_features.to(cfg.device)\n",
    "                    labels = labels.to(cfg.device)\n",
    "                    with autocast(enabled=cfg.apex):\n",
    "                        loss, output = model(inputs, numerical_features, labels)\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'loss': loss.item(),\n",
    "                        'lr': scheduler.get_lr()[0]\n",
    "                    })\n",
    "                    train_losses.append(loss.item() * len(labels))\n",
    "                    train_nums.append(len(labels))\n",
    "\n",
    "                    if cfg.gradient_accumulation_steps > 1:\n",
    "                        loss = loss / cfg.gradient_accumulation_steps\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    # FGM attack\n",
    "                    # fgm.attack()\n",
    "                    # with autocast(enabled=cfg.apex):\n",
    "                    #     loss_adv, _ = model(inputs, labels)\n",
    "                    # scaler.scale(loss_adv).backward()\n",
    "                    # fgm.restore()\n",
    "                    \n",
    "                    if cfg.clip_grad_norm is not None:\n",
    "                        # scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            model.parameters(),\n",
    "                            cfg.clip_grad_norm\n",
    "                        )\n",
    "                        \n",
    "                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        scheduler.step()\n",
    "\n",
    "                    if step % cfg.eval_step == 0 and step != 0:\n",
    "                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n",
    "                        best_val_preds, best_val_score = evaluating(\n",
    "                            cfg, valid_loader,\n",
    "                            model,\n",
    "                            valid_df,\n",
    "                            fold,\n",
    "                            best_val_preds,\n",
    "                            best_val_score,\n",
    "                        )\n",
    "                        model.train()\n",
    "\n",
    "            train_loss = sum(train_losses)/sum(train_nums)\n",
    "            train_log = {\n",
    "                'train_loss':train_loss\n",
    "            }\n",
    "            display(train_log)\n",
    "\n",
    "            # evaluating(epoch)\n",
    "            print(f'fold: {fold}, epoch: {epoch}, complete')\n",
    "            best_val_preds, best_val_score = evaluating(\n",
    "                cfg, valid_loader,\n",
    "                model,\n",
    "                valid_df,\n",
    "                fold,\n",
    "                best_val_preds,\n",
    "                best_val_score,\n",
    "            )\n",
    "\n",
    "        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n",
    "        np.save(cfg.EXP_PREDS / f'oof_pred_fold{fold}.npy', best_val_preds)\n",
    "        fold_score.append(best_val_score)\n",
    "        del model; gc.collect()\n",
    "\n",
    "    np.save(cfg.EXP_PREDS / 'oof_pred.npy', oof_pred)\n",
    "\n",
    "    # =====================\n",
    "    # scoring\n",
    "    # =====================\n",
    "    score = mcrmse(cfg, oof_pred, train)\n",
    "    print('fold score：', fold_score)\n",
    "    print('CV:', round(score, 4))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba9659-8a32-4eae-abe5-3bb09fbd1fb4",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393a583a-01fa-47fe-ad15-d26a818e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3924af229d5e460d92c9ffc8ffff0e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0, step: 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f6bcb399b9452daf9cf75160601869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 1.604088484312822\n",
      "wording rmse: 1.238720074734416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.685250988572917, 'mcrmse': 1.421404279523619}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 0, epoch: 0, step: 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbad55518e2447e69154ffbcfec9e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.993440918454915\n",
      "wording rmse: 0.8246679087562335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.3119095613333926, 'mcrmse': 0.9090544136055743}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.6157653385763446}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b4239541634b4ca4fbe25bae77c086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 1.061118372588343\n",
      "wording rmse: 1.1061465605029357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.461611336075168, 'mcrmse': 1.0836324665456394}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f874a5ad8cdd4b74ac41bd0d8bbed230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, step: 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b925ca91ee5488b9b8b8065b4221bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 1.061118372588343\n",
      "wording rmse: 1.1061465605029357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.461611336075168, 'mcrmse': 1.0836324665456394}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 1, step: 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3d604ace5e45599d7849140426797d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 1.061118372588343\n",
      "wording rmse: 1.1061465605029357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.461611336075168, 'mcrmse': 1.0836324665456394}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfolds \u001b[38;5;241m=\u001b[39m get_commonlit_fold(train_df)\n\u001b[1;32m     25\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfolds\u001b[38;5;241m.\u001b[39mto_csv(cfg\u001b[38;5;241m.\u001b[39mEXP_PREDS \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfolds.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_feat_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [16], line 127\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(cfg, train, train_feats)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    125\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m cfg\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m--> 127\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# FGM attack\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# fgm.attack()\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# with autocast(enabled=cfg.apex):\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#     loss_adv, _ = model(inputs, labels)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# scaler.scale(loss_adv).backward()\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# fgm.restore()\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mclip_grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# scaler.unscale_(optimizer)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train_df = pd.read_csv(cfg.INPUT / \"summaries_train.csv\")\n",
    "prompts_train_df = pd.read_csv(cfg.INPUT / \"prompts_train.csv\")\n",
    "\n",
    "\n",
    "train_df = train_df.merge(prompts_train_df, on=\"prompt_id\")\n",
    "train_df = processing_features(train_df)\n",
    "train_feat_df = feature_engineering(train_df)\n",
    "\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n",
    "cfg.tokenizer.save_pretrained(cfg.EXP / 'tokenizer')\n",
    "cfg.folds = get_commonlit_fold(train_df)\n",
    "cfg.folds.to_csv(cfg.EXP_PREDS / 'folds.csv')\n",
    "score = training(cfg, train_df, train_feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0c74f25-b56e-45e1-b540-7cfd7c55e6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>mean_num_words</th>\n",
       "      <th>mean_num_unique_words</th>\n",
       "      <th>num_slash</th>\n",
       "      <th>paragraph_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>syntax_count</th>\n",
       "      <th>...</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>text_standard_float</th>\n",
       "      <th>spache_readability</th>\n",
       "      <th>rix</th>\n",
       "      <th>lix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.04</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>3.00</td>\n",
       "      <td>36.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>138</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>14.50</td>\n",
       "      <td>13.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.24</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>9.15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.64</td>\n",
       "      <td>40.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.63</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>8.13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.80</td>\n",
       "      <td>35.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>19.00</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>10.97</td>\n",
       "      <td>14.1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>14.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.77</td>\n",
       "      <td>6.00</td>\n",
       "      <td>48.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.81</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>8.36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3.00</td>\n",
       "      <td>39.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>33.00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.2</td>\n",
       "      <td>9.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.54</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>18.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.00</td>\n",
       "      <td>54.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15.00</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.33</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>7.00</td>\n",
       "      <td>53.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>7.75</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.30</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>16.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.08</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.92</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.79</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.67</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>14.75</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.02</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>8.56</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.67</td>\n",
       "      <td>31.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_words  n_unique_words  num_sentences  is_upper  mean_num_words  \\\n",
       "0          61              51              4      True           15.25   \n",
       "1         203             138             14      True           14.50   \n",
       "2          60              50              6      True           10.00   \n",
       "3          76              59              4      True           19.00   \n",
       "4          27              25              3      True            9.00   \n",
       "...       ...             ...            ...       ...             ...   \n",
       "7160       33              30              1      True           33.00   \n",
       "7161       30              27              2      True           15.00   \n",
       "7162       29              22              4      True            7.75   \n",
       "7163       49              35              4      True           12.50   \n",
       "7164       59              42              4      True           14.75   \n",
       "\n",
       "      mean_num_unique_words  num_slash  paragraph_count  upper_count  \\\n",
       "0                 15.000000          0                0     0.000000   \n",
       "1                 13.785714          0                0     0.000000   \n",
       "2                  9.666667          0                0     0.000000   \n",
       "3                 16.500000          0                0     0.000000   \n",
       "4                  8.666667          0                0     0.000000   \n",
       "...                     ...        ...              ...          ...   \n",
       "7160              30.000000          0                0     0.000000   \n",
       "7161              13.500000          0                0     0.000000   \n",
       "7162               6.750000          0                0     0.034483   \n",
       "7163              11.000000          0                0     0.040816   \n",
       "7164              12.250000          0                0     0.000000   \n",
       "\n",
       "      syntax_count  ...  automated_readability_index  coleman_liau_index  \\\n",
       "0                0  ...                          8.3                9.04   \n",
       "1                5  ...                          9.5               10.43   \n",
       "2                0  ...                          7.0                8.63   \n",
       "3                5  ...                         14.5               10.97   \n",
       "4                0  ...                          6.1                7.24   \n",
       "...            ...  ...                          ...                 ...   \n",
       "7160             1  ...                         16.2                9.12   \n",
       "7161             2  ...                         14.6                8.66   \n",
       "7162             0  ...                          3.2                5.02   \n",
       "7163             1  ...                         10.6               11.08   \n",
       "7164             1  ...                          7.2                5.51   \n",
       "\n",
       "      smog_index  dale_chall_readability_score  linsear_write_formula  \\\n",
       "0           10.7                          7.76               8.375000   \n",
       "1           10.1                          8.24               6.625000   \n",
       "2            9.4                          8.71               6.200000   \n",
       "3           14.1                          8.84              16.333333   \n",
       "4            0.0                          7.81               6.750000   \n",
       "...          ...                           ...                    ...   \n",
       "7160         0.0                         10.54              20.500000   \n",
       "7161         0.0                          9.34              16.000000   \n",
       "7162         3.1                          6.30               3.833333   \n",
       "7163         9.7                          9.92               8.500000   \n",
       "7164         6.4                          7.02              10.166667   \n",
       "\n",
       "      gunning_fog  text_standard_float  spache_readability   rix    lix  \n",
       "0            9.40                  8.0                4.54  3.00  36.61  \n",
       "1            9.15                 10.0                4.32  3.64  40.61  \n",
       "2            8.13                  9.0                4.11  2.80  35.33  \n",
       "3           14.33                 15.0                5.77  6.00  48.98  \n",
       "4            8.36                  7.0                4.34  3.00  39.43  \n",
       "...           ...                  ...                 ...   ...    ...  \n",
       "7160        18.05                 14.0                7.58  7.00  54.21  \n",
       "7161        13.33                  9.0                6.79  7.00  53.33  \n",
       "7162         3.88                  4.0                2.80  0.67  16.60  \n",
       "7163         9.79                 10.0                5.25  5.67  50.99  \n",
       "7164         8.56                  6.0                4.05  1.67  31.56  \n",
       "\n",
       "[7165 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d95700-faaa-46e9-af14-7aa42e334a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
