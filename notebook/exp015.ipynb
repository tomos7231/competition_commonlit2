{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf29c80-f629-4a89-8ac9-55d250722bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pyspellchecker textstat lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef23f706-f84a-4274-a21f-62d3ceb0b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"commonlit-exp015-deberta-v3-base\"\n",
    "    MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "    ROOT = \"/notebooks\"\n",
    "\n",
    "    apex=True\n",
    "    seed = 42\n",
    "    num_fold = 4\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    batch_size = 16\n",
    "    n_epochs = 3\n",
    "    max_len = 768\n",
    "    target_list = [\"content\", \"wording\"]\n",
    "    n_targets = len(target_list)\n",
    "    \n",
    "    weight_decay = 0.01\n",
    "    scheduler='cosine'\n",
    "    betas = (0.9, 0.999)\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    lr_weight_decay = 0.98\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    eval_step = 150\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps_rate=0.1\n",
    "    clip_grad_norm = 1000\n",
    "    gradient_accumulation_steps = 1\n",
    "    \n",
    "    # GPU Optimize Settings\n",
    "    gpu_optimize_config= {\n",
    "        \"freezing\": False,\n",
    "        \"gradient_checkpoint\": True\n",
    "    }\n",
    "    \n",
    "    model_params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"metric\": \"regression\",\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"random_state\": seed,\n",
    "    }\n",
    "    \n",
    "    lgb_train_params = {\n",
    "        \"num_boost_round\": 999999,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e005db68-c9ac-4d8f-9cf0-0ad993be0bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.10.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1821.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1+cu113) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.10.1+cu113\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting text-unidecode\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: text-unidecode\n",
      "Successfully installed text-unidecode-1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import pickle\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import textstat\n",
    "\n",
    "! pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "!pip install text-unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab3cbd-a73c-4b3f-aee6-cf7b3bb3e257",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a32846-749b-4981-bd31-94c4beeb650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install -qq transformers==4.16.2\n",
    "    ! pip install -qq tokenizers==0.11.6\n",
    "    ! pip install -qq transformers[sentencepiece]\n",
    "\n",
    "    # set dirs    \n",
    "    cfg.INPUT = Path(f\"{cfg.ROOT}/input\")\n",
    "    cfg.OUTPUT = Path(f\"{cfg.ROOT}/output\")\n",
    "    cfg.EXP = cfg.OUTPUT / cfg.NAME\n",
    "\n",
    "    cfg.api_path = f\"{cfg.ROOT}/kaggle.json\"\n",
    "\n",
    "    cfg.EXP_MODEL = cfg.EXP / \"model\"\n",
    "    cfg.EXP_PREDS = cfg.EXP / \"preds\"\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP, cfg.EXP_MODEL, cfg.EXP_PREDS]:\n",
    "        d.mkdir(exist_ok=True)\n",
    "        \n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9b321-c43a-4428-99d5-430ca1917b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Utils\n",
    "# =====================\n",
    "# Seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_commonlit_fold(train):\n",
    "    id2fold = {\n",
    "        \"814d6b\": 0,\n",
    "        \"39c16e\": 1,\n",
    "        \"3b9047\": 2,\n",
    "        \"ebad26\": 3,\n",
    "    }\n",
    "    train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n",
    "    return train[\"fold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0215b90-d40f-4e2b-bccb-c516afb12c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df, verbose = True):\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        if verbose:\n",
    "            print(f\"{column} rmse:\", score)\n",
    "        all_score += score/len(cfg.target_list)\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6334798-8f53-419e-a378-63d8daeda473",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b7b941-e196-4349-8aac-c3e3ca796033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e4c1c0-9232-4d4b-87ff-bec7d91653f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_features(df):\n",
    "    df['processed_text'] = df['text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "    df['full_text'] = df[\"prompt_title\"] + \" [SEP] \" + df[\"prompt_question\"] + \" [SEP] \" + df[\"processed_text\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bbe092-fe6e-476c-9078-89ec1b419986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1f3cbe-9009-4b84-9cf3-96edc5d2f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1948,\n",
      "                 from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from /root/.cache/ipython/cython/_cython_magic_0507ba6f7af5325357e70c61fd0cf3f5.c:769:\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)  # Arrayの境界チェックを無効化\n",
    "@cython.wraparound(False)   # 負のインデックスを無効化\n",
    "def longest_common_substring(str s1, str s2):\n",
    "    cdef int m, n, i, j, longest\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    # Using numpy to initialize the 2D array\n",
    "    cdef cnp.ndarray[int, ndim=2] dp = np.zeros((m+1, n+1), dtype=np.int32)\n",
    "    \n",
    "    longest = 0\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                dp[i, j] = 0\n",
    "            elif s1[i - 1] == s2[j - 1]:\n",
    "                dp[i, j] = dp[i - 1, j - 1] + 1\n",
    "                longest = max(longest, dp[i, j])\n",
    "            else:\n",
    "                dp[i, j] = 0\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed161b0-daa1-46d7-831b-28280b2d4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotes_count(row):\n",
    "    text = row['text']\n",
    "    prompt_text = row['prompt_text']\n",
    "    quotes_from_text = re.findall(r'\"([^\"]*)\"', text)\n",
    "    if len(quotes_from_text)>0:\n",
    "        return [quote in prompt_text for quote in quotes_from_text].count(True)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ngram_co_occurrence(row, n=3):\n",
    "    text = row[\"text\"]\n",
    "    prompt_text = row[\"prompt_text\"]\n",
    "\n",
    "    text_ngram = set(zip(*[text[i:] for i in range(n)]))\n",
    "    prompt_ngram = set(zip(*[prompt_text[i:] for i in range(n)]))\n",
    "    return len(text_ngram & prompt_ngram)\n",
    "\n",
    "def feature_engineering(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # basic\n",
    "    output_df[\"n_words\"] = input_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "    output_df[\"n_unique_words\"] = input_df[\"text\"].apply(lambda x: len(set(x.split())))\n",
    "    output_df[\"num_sentences\"] = input_df[\"text\"].apply(lambda x: len(x.split('.')))\n",
    "    output_df[\"is_upper\"] = input_df[\"text\"].apply(lambda x: x[0].isupper())\n",
    "    output_df[\"mean_num_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(e.split()) for e in x.split('.')]))\n",
    "    output_df[\"mean_num_unique_words\"] = input_df[\"text\"].apply(lambda x: np.mean([len(set(e.split())) for e in x.split('.')]))\n",
    "    output_df[\"num_slash\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\"))\n",
    "    output_df[\"paragraph_count\"] = input_df[\"text\"].apply(lambda x: x.count(\"\\n\\n\"))\n",
    "    output_df[\"upper_count\"] = input_df[\"text\"].apply(lambda x: np.sum([w.isupper() for w in x.split()])/len(x.split()))\n",
    "    output_df[\"syntax_count\"] = input_df[\"text\"].apply(lambda x: x.count(\",\") + x.count(\"-\") + x.count(\";\") + x.count(\":\"))\n",
    "    output_df[\"vocab_strength\"] = output_df[\"n_unique_words\"] / output_df[\"n_words\"]\n",
    "    output_df[\"new_vocab\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) - set(x[\"prompt_text\"].split())), axis=1)\n",
    "\n",
    "    # compare\n",
    "    # overwrap word\n",
    "    output_df[\"n_overwrap_unique_word\"] = input_df.apply(lambda x: len(set(x[\"text\"].split()) & set(x[\"prompt_text\"].split())), axis=1)\n",
    "    # longest common substring\n",
    "    output_df[\"longest_common_substring\"] = input_df.apply(lambda x: longest_common_substring(x[\"text\"], x[\"prompt_text\"]), axis=1)\n",
    "    # quote\n",
    "    output_df[\"quote_count\"] = input_df.apply(quotes_count, axis=1)\n",
    "    # ngram co occurrence\n",
    "    for n in [3, 4, 5, 6, 7, 8]:\n",
    "        output_df[f\"n_co_occurrence_{n}\"] = input_df.apply(ngram_co_occurrence, n=n, axis=1) / output_df[\"n_words\"]\n",
    "    \n",
    "    \n",
    "    # misspell\n",
    "    spell = SpellChecker()\n",
    "    output_df[\"n_misspell\"] = input_df[\"text\"].apply(lambda x: len(spell.unknown(x.split())))\n",
    "\n",
    "\n",
    "    output_df['automated_readability_index'] = input_df[\"text\"].apply(lambda x: textstat.automated_readability_index(x))\n",
    "    output_df['coleman_liau_index'] = input_df[\"text\"].apply(lambda x: textstat.coleman_liau_index(x))\n",
    "    output_df['smog_index'] = input_df[\"text\"].apply(textstat.smog_index)\n",
    "    output_df['dale_chall_readability_score'] = input_df[\"text\"].apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "    output_df['linsear_write_formula'] = input_df[\"text\"].apply(lambda x: textstat.linsear_write_formula(x))\n",
    "    output_df['gunning_fog'] = input_df[\"text\"].apply(textstat.gunning_fog)\n",
    "    output_df['text_standard_float'] = input_df[\"text\"].apply(textstat.text_standard, float_output=True)\n",
    "    output_df['spache_readability'] = input_df[\"text\"].apply(textstat.spache_readability)\n",
    "    output_df['rix'] = input_df[\"text\"].apply(textstat.rix)\n",
    "    output_df['lix'] = input_df[\"text\"].apply(textstat.lix)\n",
    "\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49940cc-886e-4f5f-a17e-14ad2a007857",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a44555a-ba86-4e10-9295-4bc5a5b8c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['processed_text'].to_numpy()\n",
    "        self.labels = df[cfg.target_list].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.prepare_input(self.cfg, self.text[index])\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float)\n",
    "        return inputs, label\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(cfg, text):\n",
    "        inputs = cfg.tokenizer(text,\n",
    "                               add_special_tokens=True,\n",
    "                               max_length=cfg.max_len,\n",
    "                               padding=\"max_length\",\n",
    "                               truncation=True,\n",
    "                               return_offsets_mapping=False)\n",
    "        inputs['input_ids'] = torch.tensor(\n",
    "            inputs['input_ids'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs['attention_mask'] = torch.tensor(\n",
    "            inputs['attention_mask'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a4ac4-3afd-4793-944a-2f30ad185dc7",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d234a9-f3e5-4913-a040-1d5e76f90153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.gpu_optimize_config = cfg.gpu_optimize_config\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout\": 0.,\n",
    "                \"hidden_dropout_prob\": 0.,\n",
    "                \"attention_dropout\": 0.,\n",
    "                \"attention_probs_dropout_prob\": 0.,\n",
    "            }\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            config=self.config\n",
    "        )\n",
    "\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, cfg.n_targets)\n",
    "        self._init_weights(self.fc)\n",
    "        self.ln = nn.LayerNorm(self.config.hidden_size)\n",
    "        self._init_weights(self.ln)\n",
    "\n",
    "        # Freeze\n",
    "        if self.gpu_optimize_config['freezing']:\n",
    "            freeze(self.backbone.encoder.layer[:8])\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if self.gpu_optimize_config['gradient_checkpoint']:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "        last_state = outputs[0]\n",
    "        feature = self.pool(last_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        # batch, hidden_size\n",
    "        feature = self.feature(inputs)\n",
    "        # batch, 2\n",
    "        output = self.fc(self.ln(feature))\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.SmoothL1Loss(reduction='mean')\n",
    "            loss = loss_fct(output, labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216ad9a-d7f4-40bd-af0d-4ff0ff7499aa",
   "metadata": {},
   "source": [
    "# optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975ed9d1-27e5-49d9-9f6b-cf4de08469cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_grouped_parameters(cfg, model):\n",
    "    model_type = 'backbone'\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "             'lr': cfg.decoder_lr, 'weight_decay': 0.0},\n",
    "    ]\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "    layers.reverse()\n",
    "    lr = cfg.encoder_lr\n",
    "    for layer in layers:\n",
    "        lr *= cfg.lr_weight_decay\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": cfg.weight_decay,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b424bc0d-b830-4a5d-8982-2b74b8e4ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dffaa-01c5-40d5-a307-ce6d49478ebe",
   "metadata": {},
   "source": [
    "# eval,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dcde54a-4e69-4dd0-bd89-13585a68945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(cfg, valid_loader, model, valid_df, fold, best_val_preds, best_val_score):\n",
    "    val_preds = []\n",
    "    val_losses = []\n",
    "    val_nums = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n",
    "            for (inputs, labels) in pbar:\n",
    "                inputs = collate(inputs)\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(cfg.device)\n",
    "                labels = labels.to(cfg.device)\n",
    "                with autocast():\n",
    "                    loss, output = model(inputs, labels)\n",
    "                \n",
    "                output = output.detach().cpu().numpy()\n",
    "                val_preds.append(output)\n",
    "                val_losses.append(loss.item() * len(labels))\n",
    "                val_nums.append(len(labels))\n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': loss.item()\n",
    "                })\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_loss = sum(val_losses) / sum(val_nums)\n",
    "    score = mcrmse(cfg, val_preds, valid_df)\n",
    "\n",
    "    val_log = {\n",
    "        'val_loss': val_loss,\n",
    "        'mcrmse': score\n",
    "    }\n",
    "    display(val_log)\n",
    "\n",
    "    if best_val_score > score:\n",
    "        print('\\033[31m'+'save model weight'+'\\033[0m')\n",
    "        best_val_preds = val_preds\n",
    "        best_val_score = score\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            cfg.EXP_MODEL / f\"fold{fold}.pth\"\n",
    "        )\n",
    "    \n",
    "    return best_val_preds, best_val_score\n",
    "\n",
    "def training(cfg, train):\n",
    "    # =====================\n",
    "    # Training\n",
    "    # =====================\n",
    "    set_seed(cfg.seed)\n",
    "    oof_pred = np.zeros((len(train), 2), dtype=np.float32)\n",
    "    fold_score = []\n",
    "\n",
    "    for fold in cfg.trn_fold:\n",
    "        # dataset, dataloader\n",
    "        train_df = train.loc[cfg.folds!=fold]\n",
    "        valid_df = train.loc[cfg.folds==fold]\n",
    "        train_idx = list(train_df.index)\n",
    "        valid_idx = list(valid_df.index)\n",
    "\n",
    "        # Datasetの設定\n",
    "        train_dataset = TrainDataset(cfg, train_df)\n",
    "        valid_dataset = TrainDataset(cfg, valid_df)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=cfg.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # model\n",
    "        model = CustomModel(cfg)\n",
    "        torch.save(model.config, cfg.EXP_MODEL / 'config.pth')\n",
    "        model = model.to(cfg.device)\n",
    "\n",
    "        # optimizer, scheduler\n",
    "        optimizer_grouped_parameters = get_optimizer_grouped_parameters(cfg, model)\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        num_train_steps = int(len(train_df) / cfg.batch_size * cfg.n_epochs)\n",
    "        scheduler = get_scheduler(cfg, optimizer, num_train_steps)\n",
    "\n",
    "        # enable FGM\n",
    "        # fgm = FGM(model)\n",
    "\n",
    "        # model-training\n",
    "        best_val_preds = None\n",
    "        best_val_score = 9999\n",
    "        \n",
    "        for epoch in range(cfg.n_epochs):\n",
    "            # training\n",
    "            print(f\"# ============ start epoch:{epoch} ============== #\")\n",
    "            train_losses = []\n",
    "            train_nums = []\n",
    "            model.train() \n",
    "            scaler = GradScaler(enabled=cfg.apex)\n",
    "            with tqdm(train_loader, total=len(train_loader)) as pbar:\n",
    "                for step, (inputs, labels) in enumerate(pbar):\n",
    "                    inputs = collate(inputs)\n",
    "                    for k, v in inputs.items():\n",
    "                        inputs[k] = v.to(cfg.device)\n",
    "                    labels = labels.to(cfg.device)\n",
    "                    with autocast(enabled=cfg.apex):\n",
    "                        loss, output = model(inputs, labels)\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'loss': loss.item(),\n",
    "                        'lr': scheduler.get_lr()[0]\n",
    "                    })\n",
    "                    train_losses.append(loss.item() * len(labels))\n",
    "                    train_nums.append(len(labels))\n",
    "\n",
    "                    if cfg.gradient_accumulation_steps > 1:\n",
    "                        loss = loss / cfg.gradient_accumulation_steps\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    # FGM attack\n",
    "                    # fgm.attack()\n",
    "                    # with autocast(enabled=cfg.apex):\n",
    "                    #     loss_adv, _ = model(inputs, labels)\n",
    "                    # scaler.scale(loss_adv).backward()\n",
    "                    # fgm.restore()\n",
    "                    \n",
    "                    if cfg.clip_grad_norm is not None:\n",
    "                        # scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            model.parameters(),\n",
    "                            cfg.clip_grad_norm\n",
    "                        )\n",
    "                        \n",
    "                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        scheduler.step()\n",
    "\n",
    "                    if step % cfg.eval_step == 0 and step != 0:\n",
    "                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n",
    "                        best_val_preds, best_val_score = evaluating(\n",
    "                            cfg, valid_loader,\n",
    "                            model,\n",
    "                            valid_df,\n",
    "                            fold,\n",
    "                            best_val_preds,\n",
    "                            best_val_score,\n",
    "                        )\n",
    "                        model.train()\n",
    "\n",
    "            train_loss = sum(train_losses)/sum(train_nums)\n",
    "            train_log = {\n",
    "                'train_loss':train_loss\n",
    "            }\n",
    "            display(train_log)\n",
    "\n",
    "            # evaluating(epoch)\n",
    "            print(f'fold: {fold}, epoch: {epoch}, complete')\n",
    "            best_val_preds, best_val_score = evaluating(\n",
    "                cfg, valid_loader,\n",
    "                model,\n",
    "                valid_df,\n",
    "                fold,\n",
    "                best_val_preds,\n",
    "                best_val_score,\n",
    "            )\n",
    "\n",
    "        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n",
    "        np.save(cfg.EXP_PREDS / f'oof_pred_fold{fold}.npy', best_val_preds)\n",
    "        fold_score.append(best_val_score)\n",
    "        del model; gc.collect()\n",
    "\n",
    "    np.save(cfg.EXP_PREDS / 'oof_pred.npy', oof_pred)\n",
    "\n",
    "    # =====================\n",
    "    # scoring\n",
    "    # =====================\n",
    "    score = mcrmse(cfg, oof_pred, train)\n",
    "    print('fold score：', fold_score)\n",
    "    print('CV:', round(score, 4))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba9659-8a32-4eae-abe5-3bb09fbd1fb4",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "393a583a-01fa-47fe-ad15-d26a818e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train_df = pd.read_csv(cfg.INPUT / \"summaries_train.csv\")\n",
    "feedback3_pred = pd.read_csv(cfg.INPUT / \"pred_feedback3value.csv\")\n",
    "prompts_train_df = pd.read_csv(cfg.INPUT / \"prompts_train.csv\")\n",
    "\n",
    "\n",
    "train_df = train_df.merge(prompts_train_df, on=\"prompt_id\")\n",
    "train_df = processing_features(train_df)\n",
    "train_feat_df = feature_engineering(train_df)\n",
    "\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n",
    "cfg.tokenizer.save_pretrained(cfg.EXP / 'tokenizer')\n",
    "cfg.folds = get_commonlit_fold(train_df)\n",
    "cfg.folds.to_csv(cfg.EXP_PREDS / 'folds.csv')\n",
    "# score = training(cfg, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58a35a42-2272-4809-a658-0416a5e47f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.load(cfg.EXP_PREDS / \"oof_pred.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b16a1b82-a48d-4b76-8761-1f26dd2ba9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content rmse: 0.4908670044369746\n",
      "wording rmse: 0.6666679293767223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5787674669068484"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcrmse(cfg, oof, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87e66460-56e4-42b4-90ba-de8544f966cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>2.396729</td>\n",
       "      <td>2.672852</td>\n",
       "      <td>2.837891</td>\n",
       "      <td>2.824707</td>\n",
       "      <td>3.123535</td>\n",
       "      <td>2.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>2.030029</td>\n",
       "      <td>2.591553</td>\n",
       "      <td>2.833984</td>\n",
       "      <td>2.641113</td>\n",
       "      <td>3.173828</td>\n",
       "      <td>3.090332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3.397461</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>3.900391</td>\n",
       "      <td>3.691406</td>\n",
       "      <td>3.817871</td>\n",
       "      <td>3.704102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>1.791992</td>\n",
       "      <td>2.041748</td>\n",
       "      <td>2.305664</td>\n",
       "      <td>1.999512</td>\n",
       "      <td>2.478516</td>\n",
       "      <td>2.051514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>3.356934</td>\n",
       "      <td>3.525879</td>\n",
       "      <td>3.588379</td>\n",
       "      <td>3.570801</td>\n",
       "      <td>3.838867</td>\n",
       "      <td>3.120117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  000e8c3c7ddb  2.396729  2.672852    2.837891     2.824707  3.123535   \n",
       "1  0020ae56ffbf  2.030029  2.591553    2.833984     2.641113  3.173828   \n",
       "2  004e978e639e  3.397461  3.453125    3.900391     3.691406  3.817871   \n",
       "3  005ab0199905  1.791992  2.041748    2.305664     1.999512  2.478516   \n",
       "4  0070c9e7af47  3.356934  3.525879    3.588379     3.570801  3.838867   \n",
       "\n",
       "   conventions  \n",
       "0     2.683594  \n",
       "1     3.090332  \n",
       "2     3.704102  \n",
       "3     2.051514  \n",
       "4     3.120117  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback3_pred = feedback3_pred.drop('prompt_id', axis = 1)\n",
    "feedback3_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffcb3ed0-c6fc-4afa-8750-8ce2a6d76bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>fold</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>The Third Wave [SEP] Summarize how the Third W...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.396729</td>\n",
       "      <td>2.672852</td>\n",
       "      <td>2.837891</td>\n",
       "      <td>2.824707</td>\n",
       "      <td>3.123535</td>\n",
       "      <td>2.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>The Third Wave [SEP] Summarize how the Third W...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.356934</td>\n",
       "      <td>3.525879</td>\n",
       "      <td>3.588379</td>\n",
       "      <td>3.570801</td>\n",
       "      <td>3.838867</td>\n",
       "      <td>3.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0095993991fe</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave only started as an experiment w...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The third wave only started as an experiment w...</td>\n",
       "      <td>The Third Wave [SEP] Summarize how the Third W...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.791992</td>\n",
       "      <td>3.128906</td>\n",
       "      <td>3.239746</td>\n",
       "      <td>3.071777</td>\n",
       "      <td>3.533691</td>\n",
       "      <td>3.151855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c20c6ddd23</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The experimen was orginally about how even whe...</td>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.969062</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The experimen was orginally about how even whe...</td>\n",
       "      <td>The Third Wave [SEP] Summarize how the Third W...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.798828</td>\n",
       "      <td>3.072266</td>\n",
       "      <td>3.127441</td>\n",
       "      <td>3.021973</td>\n",
       "      <td>3.525391</td>\n",
       "      <td>2.914551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d40ad10dc9</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave developed so quickly due to the...</td>\n",
       "      <td>-0.910596</td>\n",
       "      <td>-0.081769</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The third wave developed so quickly due to the...</td>\n",
       "      <td>The Third Wave [SEP] Summarize how the Third W...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.040283</td>\n",
       "      <td>2.347656</td>\n",
       "      <td>2.579102</td>\n",
       "      <td>2.284912</td>\n",
       "      <td>2.774414</td>\n",
       "      <td>2.298828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "2  0095993991fe    814d6b  The third wave only started as an experiment w...   \n",
       "3  00c20c6ddd23    814d6b  The experimen was orginally about how even whe...   \n",
       "4  00d40ad10dc9    814d6b  The third wave developed so quickly due to the...   \n",
       "\n",
       "    content   wording                                    prompt_question  \\\n",
       "0  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
       "1  3.272894  3.219757  Summarize how the Third Wave developed over su...   \n",
       "2  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
       "3  0.567975  0.969062  Summarize how the Third Wave developed over su...   \n",
       "4 -0.910596 -0.081769  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "     prompt_title                                        prompt_text  \\\n",
       "0  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "1  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "2  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "4  The Third Wave  Background \\r\\nThe Third Wave experiment took ...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  The third wave was an experimentto see how peo...   \n",
       "1  The Third Wave developed  rapidly because the ...   \n",
       "2  The third wave only started as an experiment w...   \n",
       "3  The experimen was orginally about how even whe...   \n",
       "4  The third wave developed so quickly due to the...   \n",
       "\n",
       "                                           full_text  fold  cohesion  \\\n",
       "0  The Third Wave [SEP] Summarize how the Third W...     0  2.396729   \n",
       "1  The Third Wave [SEP] Summarize how the Third W...     0  3.356934   \n",
       "2  The Third Wave [SEP] Summarize how the Third W...     0  2.791992   \n",
       "3  The Third Wave [SEP] Summarize how the Third W...     0  2.798828   \n",
       "4  The Third Wave [SEP] Summarize how the Third W...     0  2.040283   \n",
       "\n",
       "     syntax  vocabulary  phraseology   grammar  conventions  \n",
       "0  2.672852    2.837891     2.824707  3.123535     2.683594  \n",
       "1  3.525879    3.588379     3.570801  3.838867     3.120117  \n",
       "2  3.128906    3.239746     3.071777  3.533691     3.151855  \n",
       "3  3.072266    3.127441     3.021973  3.525391     2.914551  \n",
       "4  2.347656    2.579102     2.284912  2.774414     2.298828  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(feedback3_pred, on=\"student_id\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2044b-0a59-431c-952c-1e6074beab68",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a57c069c-81db-4d5e-b4d6-36a7213ee92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>mean_num_words</th>\n",
       "      <th>mean_num_unique_words</th>\n",
       "      <th>num_slash</th>\n",
       "      <th>paragraph_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>syntax_count</th>\n",
       "      <th>vocab_strength</th>\n",
       "      <th>new_vocab</th>\n",
       "      <th>n_overwrap_unique_word</th>\n",
       "      <th>longest_common_substring</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>n_co_occurrence_3</th>\n",
       "      <th>n_co_occurrence_4</th>\n",
       "      <th>n_co_occurrence_5</th>\n",
       "      <th>n_co_occurrence_6</th>\n",
       "      <th>n_co_occurrence_7</th>\n",
       "      <th>n_co_occurrence_8</th>\n",
       "      <th>n_misspell</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>text_standard_float</th>\n",
       "      <th>spache_readability</th>\n",
       "      <th>rix</th>\n",
       "      <th>lix</th>\n",
       "      <th>pred_content</th>\n",
       "      <th>pred_wording</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.098361</td>\n",
       "      <td>2.42623</td>\n",
       "      <td>1.819672</td>\n",
       "      <td>1.245902</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.04</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.375</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.61</td>\n",
       "      <td>0.447754</td>\n",
       "      <td>1.141602</td>\n",
       "      <td>2.396729</td>\n",
       "      <td>2.672852</td>\n",
       "      <td>2.837891</td>\n",
       "      <td>2.824707</td>\n",
       "      <td>3.123535</td>\n",
       "      <td>2.683594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_words  n_unique_words  num_sentences  is_upper  mean_num_words  \\\n",
       "0       61              51              4      True           15.25   \n",
       "\n",
       "   mean_num_unique_words  num_slash  paragraph_count  upper_count  \\\n",
       "0                   15.0          0                0          0.0   \n",
       "\n",
       "   syntax_count  vocab_strength  new_vocab  n_overwrap_unique_word  \\\n",
       "0             0        0.836066         30                      21   \n",
       "\n",
       "   longest_common_substring  quote_count  n_co_occurrence_3  \\\n",
       "0                        14            0           3.098361   \n",
       "\n",
       "   n_co_occurrence_4  n_co_occurrence_5  n_co_occurrence_6  n_co_occurrence_7  \\\n",
       "0            2.42623           1.819672           1.245902           0.868852   \n",
       "\n",
       "   n_co_occurrence_8  n_misspell  automated_readability_index  \\\n",
       "0           0.557377           5                          8.3   \n",
       "\n",
       "   coleman_liau_index  smog_index  dale_chall_readability_score  \\\n",
       "0                9.04        10.7                          7.76   \n",
       "\n",
       "   linsear_write_formula  gunning_fog  text_standard_float  \\\n",
       "0                  8.375          9.4                  8.0   \n",
       "\n",
       "   spache_readability  rix    lix  pred_content  pred_wording  cohesion  \\\n",
       "0                4.54  3.0  36.61      0.447754      1.141602  2.396729   \n",
       "\n",
       "     syntax  vocabulary  phraseology   grammar  conventions  \n",
       "0  2.672852    2.837891     2.824707  3.123535     2.683594  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_cols = [f\"pred_{i}\" for i in cfg.target_list]\n",
    "train_feat_df[bert_cols] = oof\n",
    "\n",
    "feedback3_cols = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n",
    "train_feat_df[feedback3_cols] = train_df[[\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]]\n",
    "\n",
    "display(train_feat_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25d092b7-3eb3-4eaf-96a3-98bca99cae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred_lgbm = np.zeros((len(train_feat_df), 2), dtype=np.float32)\n",
    "models = []\n",
    "\n",
    "def training_lgbm(cfg, train_feat_df, target_df):\n",
    "    for fold in range(cfg.num_fold):\n",
    "        print(\"=\"*30, f\"Fold {fold}\", \"=\"*30)\n",
    "        X_train = train_feat_df.loc[cfg.folds!=fold]\n",
    "        X_valid = train_feat_df.loc[cfg.folds==fold]\n",
    "        train_idx = list(X_train.index)\n",
    "        valid_idx = list(X_valid.index)\n",
    "        \n",
    "        print(f\"Train: {X_train.shape}, Valid: {X_valid.shape}\")\n",
    "        for i, target in enumerate(cfg.target_list):\n",
    "            y_train = target_df.iloc[train_idx][target].reset_index(drop=True)\n",
    "            y_valid = target_df.iloc[valid_idx][target].reset_index(drop=True)\n",
    "\n",
    "            train_dataset = lgb.Dataset(X_train, y_train)\n",
    "            valid_dataset = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "            model = lgb.train(\n",
    "                params=cfg.model_params,\n",
    "                train_set=train_dataset,\n",
    "                valid_sets=[train_dataset, valid_dataset],\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(100),\n",
    "                    lgb.log_evaluation(1000)\n",
    "                    ],\n",
    "                **cfg.lgb_train_params\n",
    "            )\n",
    "            models.append(model)\n",
    "            pickle.dump(model, open(cfg.EXP_MODEL /  f\"lgbm_fold{fold}_{target}.pkl\", \"wb\"))\n",
    "\n",
    "            oof_pred_lgbm[valid_idx, i] = model.predict(X_valid)\n",
    "\n",
    "            score = np.sqrt(mean_squared_error(y_valid, oof_pred_lgbm[valid_idx, i]))\n",
    "\n",
    "            print(f\"Fold {fold} Target {target} RMSE: {score:.4f}\")\n",
    "\n",
    "    pickle.dump(oof, open(cfg.EXP_PREDS /  f\"oof_lgbm.pkl\", \"wb\"))\n",
    "    score = mcrmse(cfg, oof_pred_lgbm, target_df, verbose = True)\n",
    "    print(f\"Overall RMSE: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2db713b4-89c4-4004-b54b-1e300bd4007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Fold 0 ==============================\n",
      "Train: (6062, 40), Valid: (1103, 40)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's l2: 0.0998599\tvalid_1's l2: 0.233463\n",
      "Fold 0 Target content RMSE: 0.4832\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's l2: 0.150627\tvalid_1's l2: 0.443114\n",
      "Fold 0 Target wording RMSE: 0.6657\n",
      "============================== Fold 1 ==============================\n",
      "Train: (5108, 40), Valid: (2057, 40)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's l2: 0.113019\tvalid_1's l2: 0.15098\n",
      "Fold 1 Target content RMSE: 0.3886\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's l2: 0.210999\tvalid_1's l2: 0.300555\n",
      "Fold 1 Target wording RMSE: 0.5482\n",
      "============================== Fold 2 ==============================\n",
      "Train: (5156, 40), Valid: (2009, 40)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's l2: 0.110938\tvalid_1's l2: 0.237431\n",
      "Fold 2 Target content RMSE: 0.4873\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's l2: 0.214357\tvalid_1's l2: 0.412537\n",
      "Fold 2 Target wording RMSE: 0.6423\n",
      "============================== Fold 3 ==============================\n",
      "Train: (5169, 40), Valid: (1996, 40)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[303]\ttraining's l2: 0.125457\tvalid_1's l2: 0.186264\n",
      "Fold 3 Target content RMSE: 0.4316\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's l2: 0.186305\tvalid_1's l2: 0.238772\n",
      "Fold 3 Target wording RMSE: 0.4886\n",
      "content rmse: 0.44468768512220874\n",
      "wording rmse: 0.5802486002141857\n",
      "Overall RMSE: 0.51247\n"
     ]
    }
   ],
   "source": [
    "training_lgbm(cfg, train_feat_df, train_df[cfg.target_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10c33412-ff84-429e-9aea-937de9c1739e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mcrmse(cfg, \u001b[43mpreds\u001b[49m, df, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "mcrmse(cfg, preds, df, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ecbf5-c146-4996-95d5-efdc16855e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d997d0d-17a5-4c15-80f9-8f5aa1ba9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = train_df['conventions'], y = train_df['wording'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6472384-2a8b-4e7f-b34b-b3af6f312781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
